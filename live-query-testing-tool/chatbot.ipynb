{"cells": [{"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "77af57ed3480fe89", "outputId": "0fd92d1b-0452-4cc2-aafb-e65b0f11cdb2"}, "cell_type": "code", "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Mounted at /content/drive\n"]}], "execution_count": 1, "source": ["# Mount Google Drive\n", "from google.colab import drive\n", "drive.mount('/content/drive')"], "id": "77af57ed3480fe89"}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "54068ec3d6873fe9", "outputId": "e4fdbdcb-2a5b-4aca-dc0e-df31a42c851b"}, "cell_type": "code", "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25h"]}], "execution_count": 2, "source": ["# Complete setup for Google Colab\n", "!pip install -q transformers peft sentence-transformers faiss-cpu accelerate bitsandbytes"], "id": "54068ec3d6873fe9"}, {"cell_type": "code", "execution_count": 3, "id": "initial_id", "metadata": {"collapsed": true, "colab": {"base_uri": "https://localhost:8080/"}, "id": "initial_id", "outputId": "9f42a5f8-939c-4b59-cff4-09b3dbf00486"}, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["============================================================\n", "End-to-End Pipeline System\n", "============================================================\n"]}], "source": ["import torch\n", "import pandas as pd\n", "import time\n", "import pickle\n", "import faiss\n", "from sentence_transformers import SentenceTransformer\n", "from peft import PeftModel\n", "from transformers import AutoTokenizer, AutoModelForCausalLM\n", "\n", "print(\"=\"*60)\n", "print(\"End-to-End Pipeline System\")\n", "print(\"=\"*60)\n", "\n", "# Build complete pipeline class\n", "class HybridChatbot:\n", "    def __init__(self):\n", "        print(\"\\n1. Loading all components...\")\n", "\n", "        # Classifier\n", "        print(\"   - Loading classifier...\")\n", "        with open('/content/drive/MyDrive/NLP_Project/models/classifier/logistic_regression.pkl', 'rb') as f: # upload this in your drive\n", "            self.classifier = pickle.load(f)\n", "        with open('/content/drive/MyDrive/NLP_Project/models/classifier/tfidf_vectorizer.pkl', 'rb') as f: # upload this in your drive\n", "            self.tfidf = pickle.load(f)\n", "\n", "        # Retrieval system\n", "        print(\"   - Loading retrieval system...\")\n", "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n", "        self.retrieval_index = faiss.read_index('/content/drive/MyDrive/NLP_Project/models/retrieval/faiss_index.bin') # upload this in your drive\n", "        self.retrieval_data = pd.read_csv('/content/drive/MyDrive/NLP_Project/models/retrieval/deterministic_qa_pairs.csv') # upload this in your drive\n", "\n", "        # LLM\n", "        print(\"   - Loading fine-tuned LLM...\")\n", "        base_model = AutoModelForCausalLM.from_pretrained(\n", "            \"microsoft/phi-2\",\n", "            device_map=\"auto\",\n", "            trust_remote_code=True,\n", "            torch_dtype=torch.float16\n", "        )\n", "        self.llm_model = PeftModel.from_pretrained(\n", "            base_model,\n", "            \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora/final_model\" # upload this in your drive\n", "        )\n", "        self.llm_tokenizer = AutoTokenizer.from_pretrained(\n", "            \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora/final_model\" # upload this in your drive\n", "        )\n", "\n", "        print(\"   \u2713 All components loaded!\\n\")\n", "\n", "    def classify_query(self, query):\n", "        \"\"\"Returns 0 for deterministic, 1 for indeterministic\"\"\"\n", "        query_tfidf = self.tfidf.transform([query])\n", "        return self.classifier.predict(query_tfidf)[0]\n", "\n", "    def retrieve_response(self, query, k=1):\n", "        \"\"\"Semantic search for deterministic queries\"\"\"\n", "        query_embedding = self.embedding_model.encode([query], convert_to_numpy=True)\n", "        distances, indices = self.retrieval_index.search(query_embedding.astype('float32'), k)\n", "        return self.retrieval_data.iloc[indices[0][0]]['response'], distances[0][0]\n", "\n", "    def generate_response(self, query, max_tokens=150):\n", "        \"\"\"LLM generation for indeterministic queries\"\"\"\n", "        prompt = f\"Customer: {query}\\nAssistant:\"\n", "        inputs = self.llm_tokenizer(prompt, return_tensors=\"pt\").to(self.llm_model.device)\n", "\n", "        with torch.no_grad():\n", "            outputs = self.llm_model.generate(\n", "                **inputs,\n", "                max_new_tokens=max_tokens,\n", "                do_sample=True,\n", "                temperature=0.7,\n", "                top_p=0.9,\n", "                pad_token_id=self.llm_tokenizer.eos_token_id\n", "            )\n", "\n", "        response = self.llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n", "        return response.split(\"Assistant:\")[-1].strip()\n", "\n", "    def respond(self, query):\n", "        \"\"\"Main pipeline: classify \u2192 route \u2192 respond\"\"\"\n", "        start_time = time.time()\n", "\n", "        # Step 1: Classify\n", "        prediction = self.classify_query(query)\n", "        route = \"RETRIEVAL\" if prediction == 0 else \"LLM_GENERATION\"\n", "\n", "        # Step 2: Get response\n", "        if prediction == 0:  # Deterministic\n", "            response, distance = self.retrieve_response(query)\n", "            confidence = 1.0 / (1.0 + distance)  # Convert distance to confidence\n", "        else:  # Indeterministic\n", "            response = self.generate_response(query)\n", "            confidence = None\n", "\n", "        latency = (time.time() - start_time) * 1000\n", "\n", "        return {\n", "            'query': query,\n", "            'route': route,\n", "            'response': response,\n", "            'latency_ms': latency,\n", "            'confidence': confidence\n", "        }"]}, {"metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 873, "referenced_widgets": ["554293e8148e43e1af9d738e10466036", "3d7e6108fbd04ab38706d9773dae9410", "6b9e93e771cc4166980a9bac27889d1e", "560f75a5c67c43a383cca283532e84be", "d5a576a5af9748c2ba9f65c70f974ebc", "c0ef8d96f4684ed9b8f70528779e22da", "29ba6c07ed584f0a9494bfe3e587105c", "eb699c15cd1c47bf9e717a58a12ddb36", "3b2dda53a4bb427296ce0428cf0b4241", "5d61ce55d1ee4408ac4585a736add9c3", "fc71f46320a74af5b2bde333d0e78df1", "57392740202846e58bf3078bb6e31f5d", "591ab4a2e2754071984e3909bb34eb96", "64277078b3ec4945be7952639dbca207", "586df4a4cf5e44bfb3718b555a64b2c4", "48472f06ecf944658ae64a744cf77dec", "29bc5e0638f047318eceb071ffa59b24", "224c557cc9bd41dda04746bff780793c", "c05c20a89127427e91eabf65cfb8b78f", "a0ab208c86b94e659f2f05d0e1521f69", "32b732e0903b4c4d9e9974818e222464", "f8c35619c88949639b770819613255e5", "57c30b02fefe49b8bd1cbb07a2472772", "aefaf1dd41384e57a41ca86ae57e3712", "fa8dea236c9542e089397dc37068552f", "52dc0523b8e940379f7864794ff86892", "fee574207e1b4a0bb659b81250220245", "8de17befdbd0462293940f3b40e35a84", "750d67673d5d41e689fd21f62496a977", "26032b88ec97412e95da35854bde2280", "bbdcc0066d9b43ca81e525648140ab35", "e13d10f6fc71479a9d7f8e94431a7a47", "8128199fac4b4f6b954b1bfd1b8ccbb2", "b716f180fff0455d9b54bc611c3f1fe2", "2febe83303194cb990cdf1a217f4b261", "0cca91994e17420880bfd595118c0556", "a01eeec28dac407da3b785bb574499a3", "98dd7b226c76423bb21b8e261c77da7d", "950d14aea39b4f35918e7b8f51f79fe6", "bc25dad01b154855b195e137458a27dd", "02b6c4a0fa8c4209b631b8739a0a6ec4", "57290962641b4c679d0eade2f1765b5d", "a06f9c05b7e0487096e4324eb0ea2152", "d875b759a85247cb868a49028870dfef", "baab673f89504ced902245dbe31cf549", "79abd9e4480b4925bf7a095d0010531c", "dbd66451077f4cf5b641b4b35538367f", "1ad72e968aac483fad3f67d2066a0e30", "30ac0dff712f46e5be200f8353c42cb8", "d011fe3bc7d949d7a3982c5e8386f562", "4147249a698d4ee6bf17bfe1d6886b1f", "6b402a2c9a8f40f8b04ff717da83907f", "617258ab99e64713a0e30848883b361a", "e6025f8a63e44b2081e5fc0c477b4cad", "86e7a145b9154a61bca965c7a4e97e6e", "5e2882d96fc74ac4970b58ea9077f34c", "1e30920279ec468ebecc5a66d91ee5e0", "8d25cb87964243529ca1b00d19c18187", "881cc358e7e84fd5ab79b9e5cb64a063", "86fac277cb714b8a9a663cc4d3b26b1f", "0bfa6730ba114f48bb5354ca87428329", "17caa891fca3499e9e1ff9eaeac23cbe", "68ded111b4ee4b00b297e07117a065f0", "6a8b9b41ad9d461498968afbe6bcfe6f", "5f9eb4ff908c4e28bd994127e8c2d954", "9a0e95559f544869a36d36f59326389b", "06c309f36e574f418e582122bb819e34", "5f8306037e1e47c49d839137441e0c01", "1ab229f2787346a9bbf20f145f7ca46c", "07505cd443734f2a93f0d62f81050a45", "e161588b2ccb463686dab76fb2fe1201", "69c0245421f34ecc9a7afc7b3c346bd2", "130ebd20e4c54031a331f1ada8cef40e", "dfd847c20c7f4724aaae711ea3fc4f2a", "8b958a54b358460fb7097636065996c4", "dbb6fd796a7144de8b87fda42782696a", "5f46775f5cb34225ba3493dbf5620c41", "ad37b1a225774412bc4f1968b436ab08", "dd2ec57999b14f3c88b26998e591daea", "9c96fa17b43a455c8bd8fa8c1e8943b8", "c56ec58372db4416953eeccd6393cf6d", "89d7f08e3ea24443b653ded08f6cf92e", "63ed32a80cb244f3b3fd6c58cc083b8a", "6ba88bc645ea46078112b1dbc0b628d7", "2c6a6ae5042647cab29b73ea40fef2d2", "c27100d6e6cc40a596c695b3b72752c4", "3e01719509d7416da22457532c77fd87", "c2e24cf6e8234c29aab3ad63b4609b36", "bfd1733c335545819e8ecc15ace99c57", "ea2de8cd51624ce0b2df5dcbdfcae1f5", "81c2a4882bca46e2ad86601b249e5a6d", "bacd8c7b91ab4513a2c7b0249acfe28c", "97aa0d7480dd4b9f8072381acab0c1e4", "d02bcbe7ade24fbf99648830c194f949", "3e4a6c929cdd40dd989f952a4b846756", "7fa7643b5256449d9418363288b5678e", "5c4915d8d97c4bc7bbe9e03a37c23c21", "08399a1762b04425aba87b1d2f707242", "3bc739e17add40f8a98740f4d7c92680", "e94b8f4411314e638a489b511ac15d51", "3d082122c5b04c6297b435b0db324fdd", "7321c8f8a97f42c389c10bd68cec4b2a", "1bc00473ff614d1fac80313971c16191", "ec69f5aa4612441faa12b7d1f529e04c", "2d49966bfeb44dabbd863394665b0461", "e9fa911b46ce417fb5f54f51feab192a", "f457619e2f1c4c9f9d0130f4ea14ef85", "13a5f4190f0b46c9bc9eea3503700e5e", "f9cad7c1f13f4ef5a9e6849ed71c7140", "c668a87f5277442fa7abdb53bfb564b4", "8835d5dd261749d9a61d68ab531ea9d0", "1374514cbfb343fb99789a692f25b052", "e26392c714154c5a8be17c684bafb5d0", "1652657e54404efea4d41262f511088d", "db85ae32e5044b75b4ce3122408cc2ad", "04a5af9efc0b4a388f3069f67a542865", "c27c776ed35b4fcbbd3e1d6a82872df2", "34246b1b41ef46248cc37df560a5b5c8", "686aea54c6d846219032a7a50147a61f", "584adc1fd3b74f4aa129764b632f542b", "638ac8deec1045cd8d765f9b82ae02a8", "abc6a72c20cd4b3b9a067c31c6b0e5cc", "0a08dc106ad9462cbf5ef9cc01bb670a", "0bdab33c940d4dc1bdcbeffeb5a588c4", "b809df1af4bf47a6be2a825b2c27f144", "bb971b25a90a40beb8a4e6cf7b6b88f9", "9e4d44f54b7549f1bd81be73f420ec65", "39bb84e175a34980a80e7f0640b3d77e", "0226f899d56341ea8404062fe08603de", "9ca45fa70e114e94ab38e5aa0375b467", "ccc0d7accd4c46c8a2a6074547ed66a3", "e2f2ac65858f44a7a37469381ce9a8b6", "c6cc4ef07887450cbdf5bbd2d9688940", "14287cc33fa4419eb7712f10005b2a66", "1c990fb7ed454d58beca9fb1f9b265fc", "64bb5a826cd142eeb4fb2e13164bfc97", "4e296f1e41e3445c9e2f54b56b5c0d2f", "ab447d328580496da79fa6041cab59c8", "2529ad00843846a198128a77d92c6303", "e015b273bb7044d5964d154ae7836024", "f28aaf76df424f338c5cedab1163e0f3", "033926ff325d47cda8a4f150948b9064", "0e5810c5cf3744079e790981217e50c1", "6dcf7fd887fb466eaffa48ee4c036f0a", "05580f759b504f51bc0ae81bf6b6b0dd", "9644382a65cb4bcabc64543025b3b28a", "5862be8a445342d5869085514e5fe353", "5cc4f7822b78427cb338a23f8594e182", "fca56711693848fda6e9e00f4e0e352a", "702b9fb256f54256b4b7721a5dd1ccf4", "214e4fc0f04a47ceb990890eb25fe99f", "ff1f8a43e0434c7f975c467e22b4563a", "e47045618c214650bb69e399dc393804", "f71b685c87eb466d8ed619022653e37e", "6736a53f33784863ae35584b09c0f77b", "fe17ad2fbe244047b8c9f797f6edd9ed", "511cf251f4394bd1a4c7918243e33bb2", "cd472c72436e4cea87f2276a0ac8896b", "24608814215e4b7b9de3b3150550063d", "e4021a7591024959a1b2cd852ef75e99", "a453a66495d04e6c8b5c93d37ab50698", "be23b5809f69414badb3babacc682ffd", "2ced0192a48f4d2a9ebccc5fab6a5cea", "b9804953371f484c88cf7db39bc9adb3", "0a3188fb3e9f414ba4e7d564ab99aa84", "09d3691af1214c52a10251089b08a771", "e35e3ef0ec9a4592b252a678ec7c50e3", "42b1b277d295471f9a61901818c664bf", "4e5360b469ee481ea292b5c7e4236f4c", "dca89cc808b342cd9ff485fe39fac07e", "05a6ba292db747a3a9099d214180a68c", "a81ae0d2f35a4a3a8d7bd89d306db8fb", "9647aa53c01a47079a52fa44f30ee712", "10050aa24b4f4d5eacf1a5b17d1d968c", "e261f49d3b4040d186dace151224610a", "a75fe766ba0f45a2b77bc50bf54f15e2", "f77bb22ce27e439e8657f697a2fe9c45", "82143e81a4e44d8b91a23a1c51afe65f", "87d4d84a9d9445c5b5992bf56ca700e7", "2adecb14f7b64f7f887fbb9f742a5a11", "c0a8f6eed2734bc5b30af9c5fa9d5c85", "35c471cf90ef43ec9c71106f28d0b9ae", "8d50bac9dff34ec0ba754e18f97278e7", "072162a16d9e4fe3a3c0c55a543b4193", "6c26a9e65f204d7293f189a9a6bc3688", "b08ba25dbe454bcb946fbe6259a724a7", "ffc4f9c8ce5e420696353a9d9a5e4fca", "083de8f6a6c740efba559ff56983a310", "8601292b84254dacb381489d096d6b44", "ab146539d67841fcb85a31b6c9624524", "cebb1a60a47949e49398b491dce756fa", "6dd75f4212714a00b5a67811f706b6b5", "db1f940d8327448cad5e795ff7adb788", "b91b62df0b9746df9f275d034e2ba7ce", "2b228d43c00847aa9bf52d26a1005ee0", "67218eb9de7a4218bde984d89ec639a9", "f0040a8b5a4b4d3f8c091c3f51412f51", "253630590d0b4f6c97b11df0750a27f0"]}, "id": "932c7e7f20e71731", "outputId": "6d5bcb20-953c-486f-c452-a16c1693995f"}, "cell_type": "code", "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\n", "1. Loading all components...\n", "   - Loading classifier...\n", "   - Loading retrieval system...\n"]}, {"output_type": "stream", "name": "stderr", "text": ["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n", "The secret `HF_TOKEN` does not exist in your Colab secrets.\n", "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n", "You will be able to reuse this secret in all of your notebooks.\n", "Please note that authentication is recommended but still optional to access public models or datasets.\n", "  warnings.warn(\n"]}, {"output_type": "display_data", "data": {"text/plain": ["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "554293e8148e43e1af9d738e10466036"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "57392740202846e58bf3078bb6e31f5d"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["README.md: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "57c30b02fefe49b8bd1cbb07a2472772"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b716f180fff0455d9b54bc611c3f1fe2"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "baab673f89504ced902245dbe31cf549"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5e2882d96fc74ac4970b58ea9077f34c"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "06c309f36e574f418e582122bb819e34"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["vocab.txt: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ad37b1a225774412bc4f1968b436ab08"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "bfd1733c335545819e8ecc15ace99c57"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e94b8f4411314e638a489b511ac15d51"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8835d5dd261749d9a61d68ab531ea9d0"}}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["   - Loading fine-tuned LLM...\n"]}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "abc6a72c20cd4b3b9a067c31c6b0e5cc"}}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["`torch_dtype` is deprecated! Use `dtype` instead!\n"]}, {"output_type": "display_data", "data": {"text/plain": ["model.safetensors.index.json: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c6cc4ef07887450cbdf5bbd2d9688940"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6dcf7fd887fb466eaffa48ee4c036f0a"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6736a53f33784863ae35584b09c0f77b"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "09d3691af1214c52a10251089b08a771"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f77bb22ce27e439e8657f697a2fe9c45"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "083de8f6a6c740efba559ff56983a310"}}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["   \u2713 All components loaded!\n", "\n", "{'query': \"I'm unhappy with the order I received\", 'route': 'LLM_GENERATION', 'response': \"I'm sorry to hear that you're unhappy with the order you received. Your satisfaction is of utmost importance to us, and I'm here to assist you in resolving this issue. Could you please provide me with some specific details about the problems you encountered with the order? This will help me understand the situation better and find a suitable solution for you. Thank you for bringing this to our attention, and I assure you that we will do our best to address your concerns. How can I assist you further? \\n\\nPlease let me know if there's anything else I can do to help. I appreciate your patience and understanding. Together, we will work towards resolving this matter and ensuring your satisfaction.\", 'latency_ms': 10384.51337814331, 'confidence': None}\n"]}], "execution_count": 4, "source": ["# Initialize chatbot\n", "chatbot = HybridChatbot()\n", "\n", "# Test it\n", "print(chatbot.respond(\"I'm unhappy with the order I received\"))"], "id": "932c7e7f20e71731"}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.6"}, "colab": {"provenance": [], "machine_shape": "hm", "gpuType": "A100"}, "accelerator": "GPU", "widgets": {"application/vnd.jupyter.widget-state+json": {"state": {}}}}, "nbformat": 4, "nbformat_minor": 5}