{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "A100", "collapsed_sections": ["Q4qrTqYjmUkW", "OiFKn3R2mrtF"], "machine_shape": "hm"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "widgets": {"application/vnd.jupyter.widget-state+json": {"state": {}}}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "source": ["# Phase 0: Environment Setup & Verification"], "metadata": {"id": "Q4qrTqYjmUkW"}}, {"cell_type": "markdown", "source": ["## 0.2: Mount Google Drive"], "metadata": {"id": "OiFKn3R2mrtF"}}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "7UIp6ZhWvlvD", "outputId": "c9232787-36df-4f7c-b038-802afcca005e"}, "execution_count": 2, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Mounted at /content/drive\n"]}]}, {"cell_type": "code", "source": ["from google.colab import drive\n", "drive.mount('/content/drive')\n", "\n", "# Create project directory in Drive\n", "import os\n", "project_path = '/content/drive/MyDrive/NLP_Project'\n", "os.makedirs(project_path, exist_ok=True)\n", "os.makedirs(f'{project_path}/data', exist_ok=True)\n", "os.makedirs(f'{project_path}/models', exist_ok=True)\n", "os.makedirs(f'{project_path}/results', exist_ok=True)\n", "os.makedirs(f'{project_path}/checkpoints', exist_ok=True)\n", "\n", "print(f\"\u2713 Project directory created at: {project_path}\")\n", "print(f\"\\nDirectory structure:\")\n", "!ls -la /content/drive/MyDrive/NLP_Project/"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Wkgqw1THg0DS", "outputId": "e83bc200-75bf-4bda-b875-a86ba007fb04"}, "execution_count": 3, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n", "\u2713 Project directory created at: /content/drive/MyDrive/NLP_Project\n", "\n", "Directory structure:\n", "total 16\n", "drwx------ 2 root root 4096 Dec 10 00:42 checkpoints\n", "drwx------ 2 root root 4096 Nov 19 01:28 data\n", "drwx------ 2 root root 4096 Dec 10 00:13 models\n", "drwx------ 2 root root 4096 Nov 19 01:28 results\n"]}]}, {"cell_type": "markdown", "source": ["## 0.3: Install Required Libraries"], "metadata": {"id": "VG4GckODms6r"}}, {"cell_type": "code", "source": ["print(\"Installing required packages...\")\n", "!pip install -q peft accelerate bitsandbytes\n", "!pip install -q sentence-transformers faiss-cpu\n", "!pip install -q rouge-score bert-score\n", "!pip install -q datasets\n", "!pip install -U bitsandbytes accelerate\n", "\n", "print(\"\\n\" + \"=\"*50)\n", "print(\"VERIFYING INSTALLATIONS\")\n", "print(\"=\"*50)\n", "\n", "# Verify installations\n", "import pandas as pd\n", "import numpy as np\n", "import torch\n", "from transformers import AutoTokenizer, AutoModelForCausalLM\n", "import transformers\n", "import peft\n", "import sentence_transformers\n", "from sentence_transformers import SentenceTransformer\n", "from datasets import load_dataset\n", "\n", "print(\"\u2713 All core libraries imported successfully!\")\n", "print(f\"\\nLibrary versions:\")\n", "print(f\"  PyTorch: {torch.__version__}\")\n", "print(f\"  Transformers: {transformers.__version__}\")\n", "print(f\"  PEFT: {peft.__version__}\")\n", "print(f\"  Sentence Transformers: {sentence_transformers.__version__}\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "lsxHbzmThMMb", "outputId": "25ca2066-7198-45d5-f12c-b4776ff5f0cb"}, "execution_count": 4, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Installing required packages...\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n", "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n", "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n", "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.0)\n", "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n", "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.9.0+cu126)\n", "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n", "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n", "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n", "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.3)\n", "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.36.0)\n", "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.7.0)\n", "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n", "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n", "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n", "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n", "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n", "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n", "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (75.2.0)\n", "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n", "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n", "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n", "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n", "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n", "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.80)\n", "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n", "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.4.1)\n", "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.0.4)\n", "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.7.77)\n", "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.1.2)\n", "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.4.2)\n", "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n", "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n", "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n", "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.77)\n", "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.6.85)\n", "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.11.1.6)\n", "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.5.0)\n", "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n", "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n", "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.4)\n", "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.11)\n", "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n", "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n", "\n", "==================================================\n", "VERIFYING INSTALLATIONS\n", "==================================================\n", "\u2713 All core libraries imported successfully!\n", "\n", "Library versions:\n", "  PyTorch: 2.9.0+cu126\n", "  Transformers: 4.57.3\n", "  PEFT: 0.18.0\n", "  Sentence Transformers: 5.1.2\n"]}]}, {"cell_type": "markdown", "source": ["# LLM Fine-Tuning Pilot Phi-2"], "metadata": {"id": "-DuydHstwHxI"}}, {"cell_type": "markdown", "source": ["### LoRA Setup & Small-Scale Training"], "metadata": {"id": "-PA4Gipasbgs"}}, {"cell_type": "code", "source": ["print(\"Loading MASTER TRAIN dataset...\")\n", "df_train = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/train_dataset.csv')\n", "\n", "# Filter for Indeterministic (LLM) rows from TRAIN only\n", "df_indet_train = df_train[df_train['label'] == 1].reset_index(drop=True)\n", "\n", "# Sample pilot data from this safe training set\n", "df_pilot = df_indet_train.sample(n=100, random_state=42)\n", "\n", "print(\"\\n3. Loading Phi-2 model (full precision for A100)...\")\n", "model_name = \"microsoft/phi-2\"\n", "\n", "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n", "tokenizer.pad_token = tokenizer.eos_token\n", "tokenizer.padding_side = \"right\"\n", "\n", "model = AutoModelForCausalLM.from_pretrained(\n", "    model_name,\n", "    device_map=\"auto\",\n", "    trust_remote_code=True,\n", "    torch_dtype=torch.float16  # Half precision is fine\n", ")\n", "\n", "print(f\"   \u2713 Model loaded\")\n", "print(f\"   GPU memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n", "\n", "# Prepare model for LoRA training\n", "print(\"\\n4. Preparing model for LoRA training...\")\n", "# Skip prepare_model_for_kbit_training since we're not using quantization\n", "\n", "from peft import LoraConfig, get_peft_model\n", "\n", "# LoRA configuration\n", "lora_config = LoraConfig(\n", "    r=8,  # rank\n", "    lora_alpha=16,\n", "    target_modules=[\"q_proj\", \"v_proj\"],  # Phi-2 attention modules\n", "    lora_dropout=0.05,\n", "    bias=\"none\",\n", "    task_type=\"CAUSAL_LM\"\n", ")\n", "\n", "model = get_peft_model(model, lora_config)\n", "model.print_trainable_parameters()\n", "\n", "print(f\"   \u2713 LoRA configured\")\n", "print(f\"   GPU memory after LoRA: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n", "\n", "from sklearn.model_selection import train_test_split\n", "\n", "# 1. Split the 100 pilot examples into Train (90) and Val (10)\n", "df_train_pilot, df_val_pilot = train_test_split(df_pilot, test_size=0.1, random_state=42, stratify=df_pilot['category'])\n", "\n", "# 2. Define the formatting function (Instruction -> Response)\n", "def format_prompt(row):\n", "    return f\"Customer: {row['instruction']}\\nAssistant: {row['response']}\"\n", "\n", "# 3. Create the missing text variables\n", "print(\"Formatting prompts...\")\n", "train_texts = df_train_pilot.apply(format_prompt, axis=1).tolist()\n", "val_texts = df_val_pilot.apply(format_prompt, axis=1).tolist()\n", "\n", "print(f\"Created {len(train_texts)} training prompts and {len(val_texts)} validation prompts.\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "referenced_widgets": ["ea87821b36c8419195b4f0dff70ee742", "f4c229b2461a4bc0834d113b3f913af1", "17355e1254684a1d9555e270f9305650", "3a35d7182856410fa95a0892d2535194", "12af57403486443b84f25b00c7521b93", "23a073bb006c418b9b5340de398980f4", "7c663970a81947a68e314724588031d8", "a099fbbdb88140ce9a30ea5ce228592b", "3a67f92304e04aa08107890d77f3009c", "44042b7576fe49f19e399bd0c5c76c2b", "3af59b5bfc0f423c9b5619fe9a7b3829"]}, "id": "JSVSjnODyYL7", "outputId": "cb32b784-c060-426d-dd64-8394d92cd247"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Loading MASTER TRAIN dataset...\n", "\n", "3. Loading Phi-2 model (full precision for A100)...\n"]}, {"output_type": "display_data", "data": {"text/plain": ["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ea87821b36c8419195b4f0dff70ee742"}}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["   \u2713 Model loaded\n", "   GPU memory: 11.18 GB\n", "\n", "4. Preparing model for LoRA training...\n", "trainable params: 2,621,440 || all params: 2,782,305,280 || trainable%: 0.0942\n", "   \u2713 LoRA configured\n", "   GPU memory after LoRA: 11.19 GB\n", "Formatting prompts...\n", "Created 90 training prompts and 10 validation prompts.\n"]}]}, {"cell_type": "markdown", "source": ["### Tokenization & Dataset Preparation"], "metadata": {"id": "zfBdoMghpf5j"}}, {"cell_type": "code", "source": ["from datasets import Dataset\n", "from transformers import DataCollatorForLanguageModeling\n", "\n", "print(\"\\n5. Tokenizing datasets...\")\n", "\n", "def tokenize_function(texts):\n", "    return tokenizer(\n", "        texts,\n", "        truncation=True,\n", "        max_length=512,\n", "        padding=False\n", "    )\n", "\n", "train_encodings = tokenize_function(train_texts)\n", "val_encodings = tokenize_function(val_texts)\n", "\n", "# Create HuggingFace datasets\n", "train_dataset = Dataset.from_dict({\n", "    'input_ids': train_encodings['input_ids'],\n", "    'attention_mask': train_encodings['attention_mask']\n", "})\n", "\n", "from datasets import Dataset\n", "\n", "val_dataset = Dataset.from_dict({\n", "    'input_ids': val_encodings['input_ids'],\n", "    'attention_mask': val_encodings['attention_mask']\n", "})\n", "\n", "print(f\"   \u2713 Train dataset: {len(train_dataset):,} examples\")\n", "print(f\"   \u2713 Val dataset: {len(val_dataset):,} examples\")\n", "\n", "# Data collator for causal LM\n", "data_collator = DataCollatorForLanguageModeling(\n", "    tokenizer=tokenizer,\n", "    mlm=False  # We're doing causal LM, not masked LM\n", ")\n", "\n", "print(\"   \u2713 Data collator ready\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Mq3Dk9VBwdDD", "outputId": "a98f5318-0c54-45d0-f5a6-74dfbb43b98b"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\n", "5. Tokenizing datasets...\n", "   \u2713 Train dataset: 90 examples\n", "   \u2713 Val dataset: 10 examples\n", "   \u2713 Data collator ready\n"]}]}, {"cell_type": "markdown", "source": ["### Training"], "metadata": {"id": "hyuHAsXiwiVC"}}, {"cell_type": "code", "source": ["from transformers import Trainer, TrainingArguments\n", "\n", "print(\"\\n6. Setting up training arguments...\")\n", "\n", "output_dir = '/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot'\n", "\n", "training_args = TrainingArguments(\n", "    output_dir=output_dir,\n", "    num_train_epochs=3,\n", "    per_device_train_batch_size=2,\n", "    per_device_eval_batch_size=2,\n", "    gradient_accumulation_steps=4,  # Effective batch size = 2*4 = 8\n", "    learning_rate=2e-4,\n", "    fp16=True,\n", "    logging_steps=10,\n", "    eval_strategy=\"steps\",  # Changed from evaluation_strategy\n", "    eval_steps=50,\n", "    save_steps=100,\n", "    save_total_limit=2,\n", "    load_best_model_at_end=True,\n", "    report_to=\"none\",\n", "    warmup_steps=50,\n", ")\n", "\n", "print(\"   \u2713 Training arguments configured\")\n", "print(f\"     - Epochs: {training_args.num_train_epochs}\")\n", "print(f\"     - Batch size: {training_args.per_device_train_batch_size}\")\n", "print(f\"     - Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n", "print(f\"     - Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n", "print(f\"     - Learning rate: {training_args.learning_rate}\")\n", "\n", "# Initialize trainer\n", "print(\"\\n7. Initializing Trainer...\")\n", "trainer = Trainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=train_dataset,\n", "    eval_dataset=val_dataset,\n", "    data_collator=data_collator,\n", ")\n", "\n", "print(\"   \u2713 Trainer initialized\")\n", "print(f\"   GPU memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n", "\n", "# Train!\n", "print(\"\\n8. Starting training...\")\n", "print(\"=\" * 60)\n", "\n", "import time\n", "start_time = time.time()\n", "\n", "trainer.train()\n", "\n", "elapsed_time = time.time() - start_time\n", "print(\"\\n\" + \"=\"*60)\n", "print(f\"\u2713 Training complete in {elapsed_time/60:.1f} minutes\")\n", "print(\"=\"*60)\n", "\n", "# Save final model\n", "print(\"\\n9. Saving model...\")\n", "model.save_pretrained(f\"{output_dir}/final_model\")\n", "tokenizer.save_pretrained(f\"{output_dir}/final_model\")\n", "print(f\"   \u2713 Model saved to {output_dir}/final_model\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 474}, "id": "yfWRyjkvwkCf", "outputId": "c187a0d2-769f-43f6-f45c-70f822f6aaf7"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stderr", "text": ["The model is already on multiple devices. Skipping the move to device specified in `args`.\n"]}, {"output_type": "stream", "name": "stdout", "text": ["\n", "6. Setting up training arguments...\n", "   \u2713 Training arguments configured\n", "     - Epochs: 3\n", "     - Batch size: 2\n", "     - Gradient accumulation: 4\n", "     - Effective batch size: 8\n", "     - Learning rate: 0.0002\n", "\n", "7. Initializing Trainer...\n", "   \u2713 Trainer initialized\n", "   GPU memory: 11.19 GB\n", "\n", "8. Starting training...\n", "============================================================\n"]}, {"output_type": "display_data", "data": {"text/plain": ["<IPython.core.display.HTML object>"], "text/html": ["\n", "    <div>\n", "      \n", "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n", "      [36/36 00:22, Epoch 3/3]\n", "    </div>\n", "    <table border=\"1\" class=\"dataframe\">\n", "  <thead>\n", " <tr style=\"text-align: left;\">\n", "      <th>Step</th>\n", "      <th>Training Loss</th>\n", "      <th>Validation Loss</th>\n", "    </tr>\n", "  </thead>\n", "  <tbody>\n", "  </tbody>\n", "</table><p>"]}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["\n", "============================================================\n", "\u2713 Training complete in 0.4 minutes\n", "============================================================\n", "\n", "9. Saving model...\n", "   \u2713 Model saved to /content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\n"]}]}, {"cell_type": "markdown", "source": ["### Test Generation Quality"], "metadata": {"id": "wEkNQvtEzS-F"}}, {"cell_type": "code", "source": ["print(\"=\"*60)\n", "print(\"TESTING FINE-TUNED MODEL GENERATION\")\n", "print(\"=\"*60)\n", "\n", "# Load the fine-tuned model\n", "print(\"\\n1. Loading fine-tuned model...\")\n", "from peft import PeftModel\n", "\n", "base_model = AutoModelForCausalLM.from_pretrained(\n", "    \"microsoft/phi-2\",\n", "    device_map=\"auto\",\n", "    trust_remote_code=True,\n", "    torch_dtype=torch.float16\n", ")\n", "\n", "finetuned_model = PeftModel.from_pretrained(\n", "    base_model,\n", "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n", ")\n", "\n", "tokenizer = AutoTokenizer.from_pretrained(\n", "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n", ")\n", "\n", "print(\"   \u2713 Fine-tuned model loaded\")\n", "\n", "# Test on validation examples\n", "print(\"\\n2. Generating responses for validation examples...\")\n", "\n", "test_queries = df_val_pilot['instruction'].head(5).tolist()\n", "true_responses = df_val_pilot['response'].head(5).tolist()\n", "\n", "for i, (query, true_response) in enumerate(zip(test_queries, true_responses), 1):\n", "    print(f\"\\n{'='*60}\")\n", "    print(f\"TEST EXAMPLE {i}\")\n", "    print('='*60)\n", "    print(f\"Customer Query: {query}\")\n", "    print(f\"\\nTrue Response:\\n{true_response[:300]}...\")\n", "\n", "    # Generate response\n", "    prompt = f\"Customer: {query}\\nAssistant:\"\n", "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(finetuned_model.device)\n", "\n", "    with torch.no_grad():\n", "        outputs = finetuned_model.generate(\n", "            **inputs,\n", "            max_new_tokens=200,\n", "            do_sample=True,\n", "            temperature=0.7,\n", "            top_p=0.9,\n", "            pad_token_id=tokenizer.eos_token_id\n", "        )\n", "\n", "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n", "    # Extract just the assistant response\n", "    assistant_response = generated_text.split(\"Assistant:\")[-1].strip()\n", "\n", "    print(f\"\\nGenerated Response:\\n{assistant_response}\")\n", "    print(\"-\"*60)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "referenced_widgets": ["2a09565eec4644b6ab8d9f09417e1279", "9e49a092422a414fabb344ab7fc8101f", "ba436d80db8148219ac36744f9af1c82", "4c83fb45d9b54835ad818febbb2ac8e4", "03cba42ca63941079d6d1da97dbb83ec", "383bba806c904131a32aee5233abd027", "4946674ef8ae4c08a705fc1715228a50", "2efc16e482cd4adc9fdae060cbe2cc10", "302bdb8d00bc47ee9bf98056f49b5680", "48fd6cab80fc4705a313dde15e09a7bc", "47758f8545174ca08c8c58fa2615819d"], "height": 1000}, "id": "d6bXgsHYzVZz", "outputId": "7a3f3ed9-f7e4-435a-eb6b-5f8791f512f8"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["============================================================\n", "TESTING FINE-TUNED MODEL GENERATION\n", "============================================================\n", "\n", "1. Loading fine-tuned model...\n"]}, {"output_type": "display_data", "data": {"text/plain": ["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2a09565eec4644b6ab8d9f09417e1279"}}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["   \u2713 Fine-tuned model loaded\n", "\n", "2. Generating responses for validation examples...\n", "\n", "============================================================\n", "TEST EXAMPLE 1\n", "============================================================\n", "Customer Query: is there an e-mail to send my feedbakc for ur products\n", "\n", "True Response:\n", "We appreciate your interest in providing feedback for our products! To ensure that your feedback reaches the right team, we have a dedicated email address specifically for this purpose. Please send your feedback to [productfeedback@company.com]. Our team will carefully review and consider your input...\n", "\n", "Generated Response:\n", "Yes, you can send an e-mail to our customer support team to request a backup of your product feed. To do so, please follow these steps:\n", "1. Visit our website and navigate to the customer support section.\n", "2. Look for a contact form or email address provided on the page.\n", "3. Fill out the contact form with your name, email address, and a brief message explaining the purpose of your request.\n", "4. Review the information you provided to ensure accuracy.\n", "5. Click the submit button or send the e-mail to the provided email address.\n", "6. You should receive a confirmation email from our support team acknowledging your request.\n", "7. If you do not receive a confirmation email, please check your spam or junk folder, as it may have been filtered there.\n", "8. If you still do not receive a response, please consider contacting us through a different method, such as live chat or phone support.\n", "\n", "We apologize for any inconvenience\n", "------------------------------------------------------------\n", "\n", "============================================================\n", "TEST EXAMPLE 2\n", "============================================================\n", "Customer Query: modify details on {{Account Category}} account\n", "\n", "True Response:\n", "How inspiring it is to witness your commitment to modifying the details on your {{Account Category}} account!I'm here to provide you with the necessary guidance and support throughout this process. To ensure the security of your personal information, I kindly request that you refrain from sharing an...\n", "\n", "Generated Response:\n", "Thank you for reaching out to us. We appreciate your interest in modifying the details on your {{Account Category}} account. We understand the importance of having accurate information and we are here to assist you.\n", "\n", "To begin the process, please provide us with the specific details you would like to modify. This could include updating your contact information, changing your password, or any other relevant changes you would like to make.\n", "\n", "Once you have provided the necessary details, our team will review your request and ensure that all modifications are made accordingly. We will make sure to update your account with the most accurate information and provide you with a confirmation of the changes made.\n", "\n", "If you have any further questions or require additional assistance, please feel free to reach out to us. We are here to help and ensure that your {{Account Category}} account is personalized to your needs.\n", "\n", "Thank you for choosing {{Account Category}}. We value your feedback and appreciate your support.\n", "\n", "Best regards,\n", "------------------------------------------------------------\n", "\n", "============================================================\n", "TEST EXAMPLE 3\n", "============================================================\n", "Customer Query: check status of order {{Order Number}}\n", "\n", "True Response:\n", "Thank you for contacting us! I understand that you would like to check the status of your order with the order number {{Order Number}}. To assist you with this, I recommend visiting our website and navigating to the 'Order History' section. There, you will be able to track the progress of your order...\n", "\n", "Generated Response:\n", "Hello, thank you for contacting us! I'm here to assist you with checking the status of your order. To get started, I'll need a little information from you. Could you please provide me with your order number? Once I have that, I'll be able to look into it for you and provide you with an update on its status. Thank you for your patience, and I'm here to help you every step of the way.\n", "------------------------------------------------------------\n", "\n", "============================================================\n", "TEST EXAMPLE 4\n", "============================================================\n", "Customer Query: I need assistance ordering some of your article\n", "\n", "True Response:\n", "Thank you for trusting to us for assistance in ordering some of our articles. I'm here to help you with the process and ensure a seamless experience. To better assist you, could you please provide me with the specific articles you would like to order? Once I have this information, I can guide you th...\n", "\n", "Generated Response:\n", "Sure, I'm here to help you with your article order. Could you please provide me with more details about the articles you're interested in? This will help me understand your specific needs and assist you in placing the order accurately.\n", "------------------------------------------------------------\n", "\n", "============================================================\n", "TEST EXAMPLE 5\n", "============================================================\n", "Customer Query: I want assistance to switch to the standard account\n", "\n", "True Response:\n", "I'll take care of it! Your decision to switch to our highly efficient {{Account Type}} account is commendable, and I'm here to guide you through the process:\n", "\n", "1. **Sign In:** Begin by accessing our platform and logging into your account.\n", "2. **Account Navigation:** Once you're in, locate the '{{Setti...\n", "\n", "Generated Response:\n", "I'm sorry to hear that you're having trouble with the current account you have and you'd like assistance in switching to the standard account. I'm here to help you navigate through the process and make it as seamless as possible. Could you please provide me with some more details about the issues you're facing with your current account? This will allow me to understand the specific challenges you're encountering and tailor the assistance to your needs. I want to ensure that you have a positive experience throughout this transition and that any concerns or questions you may have are addressed promptly and efficiently. Thank you for reaching out, and I'm here to support you every step of the way.\n", "------------------------------------------------------------\n"]}]}, {"cell_type": "markdown", "source": ["# Sparse Query Testing"], "metadata": {"id": "Wp85dyFeyqj9"}}, {"cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "from rouge_score import rouge_scorer\n", "import faiss\n", "from sentence_transformers import SentenceTransformer\n", "from peft import PeftModel\n", "from transformers import AutoTokenizer, AutoModelForCausalLM\n", "import torch\n", "\n", "print(\"=\"*70)\n", "print(\"STRESS TEST: Sparse Categories with Novel Wordings\")\n", "print(\"=\"*70)\n", "\n", "# Load the 100-example pilot training data used for fine-tuning\n", "print(\"\\nLoading pilot training data...\")\n", "df_train = pd.read_csv('/content/drive/MyDrive/NLP_Project/data/train_dataset.csv')\n", "df_indet_train = df_train[df_train['label'] == 1].reset_index(drop=True)\n", "df_pilot = df_indet_train.sample(n=100, random_state=42)\n", "\n", "from sklearn.model_selection import train_test_split\n", "df_train_pilot, _ = train_test_split(df_pilot, test_size=0.1, random_state=42, stratify=df_pilot['category'])\n", "\n", "# Analyze category distribution\n", "print(\"\\nCategory distribution in 100-example pilot training set:\")\n", "category_counts = df_train_pilot['category'].value_counts().sort_values()\n", "print(category_counts)\n", "\n", "# Identify sparse categories (bottom 2-3)\n", "sparse_categories = category_counts.head(2).index.tolist()\n", "print(f\"\\nIdentified SPARSE categories for testing:\")\n", "for cat in sparse_categories:\n", "    count = category_counts[cat]\n", "    print(f\"  {cat}: {count} examples\")\n", "    print(f\"  Sample queries:\")\n", "    for q in df_train_pilot[df_train_pilot['category'] == cat]['instruction'].head(2):\n", "        print(f\"    - {q}\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "JiIqBmgvysh9", "outputId": "df967f9d-d007-49d6-a619-6bf8723ccafa"}, "execution_count": 7, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["======================================================================\n", "STRESS TEST: Sparse Categories with Novel Wordings\n", "======================================================================\n", "\n", "Loading pilot training data...\n", "\n", "Category distribution in 100-example pilot training set:\n", "category\n", "FEEDBACK    19\n", "ORDER       29\n", "ACCOUNT     42\n", "Name: count, dtype: int64\n", "\n", "Identified SPARSE categories for testing:\n", "  FEEDBACK: 19 examples\n", "  Sample queries:\n", "    - i dont know what to do to write a review for a service\n", "    - how can I make a customer complaint against your company?\n", "  ORDER: 29 examples\n", "  Sample queries:\n", "    - how to swap an article of purchase {{Order Number}}?\n", "    - how do i shop an item\n"]}]}, {"cell_type": "code", "source": ["novel_queries = [\n", "    # FEEDBACK category - 7 novel wordings (19 training examples)\n", "    {\n", "        'query': \"I'd like to share my thoughts about the product quality and service I received\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Thank you for your willingness to share your thoughts about the product quality and service you received. We greatly value your feedback as it helps us improve our offerings and customer experience. To submit your review, you can visit our website and navigate to the product page, where you'll find a review section. Alternatively, you can reply to your order confirmation email with your feedback. We appreciate you taking the time to share your experience!\"\n", "    },\n", "    {\n", "        'query': \"Where can I write about my experience with your company?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"We're thrilled that you want to share your experience with our company! Customer feedback is incredibly valuable to us. You can write about your experience in several ways: on our website's review section, by replying to your order confirmation email, through our social media pages, or on third-party review platforms. Which method would be most convenient for you? We look forward to hearing about your experience!\"\n", "    },\n", "    {\n", "        'query': \"The shipping was fast but the product didn't meet my expectations - how do I let you know?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Thank you for sharing this feedback with us, and I apologize that the product didn't meet your expectations despite our fast shipping. Your honest feedback is important to us. To formally submit your review, you can visit the product page on our website and leave a detailed review there. This helps both us and other customers. Additionally, I'd like to understand more about what didn't meet your expectations so we can address this concern properly.\"\n", "    },\n", "    {\n", "        'query': \"I want to give you guys a 5-star rating, what's the best way to do that?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"We're absolutely delighted to hear you want to give us a 5-star rating! Your positive feedback means the world to us. The best ways to leave your rating are: on our website's product or service page, through the review link in your order confirmation email, or on Google Reviews and other platforms. Your 5-star rating will help other customers discover our services. Thank you so much for taking the time to share your positive experience!\"\n", "    },\n", "    {\n", "        'query': \"Can I post feedback about both the product and customer service in one place?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Absolutely! We encourage comprehensive feedback that covers both product and customer service experience. You can post combined feedback on our website's review section, where you can rate and comment on multiple aspects of your experience. This holistic feedback is incredibly valuable as it gives us a complete picture of your customer journey. Feel free to be as detailed as you'd like - we read every review carefully!\"\n", "    },\n", "    {\n", "        'query': \"I had a mixed experience and want to tell you what went well and what didn't\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"We truly appreciate your honesty and willingness to share both the positive and negative aspects of your experience. Balanced feedback like yours is incredibly valuable as it helps us understand what we're doing right and where we need to improve. Please feel free to provide your detailed review on our website's feedback section or reply to your order confirmation email. We take all feedback seriously and use it to continuously enhance our products and services.\"\n", "    },\n", "    {\n", "        'query': \"Is there a form where I can rate my recent purchase?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Yes, there certainly is! We'd love to hear your thoughts on your recent purchase. You can find our rating and review form on the product page of our website. Simply navigate to the item you purchased, scroll to the review section, and you'll see the rating form. Alternatively, check your order confirmation email - it should contain a direct link to submit your rating. Your feedback helps both us and other customers make better decisions.\"\n", "    },\n", "\n", "    # ORDER category - 7 novel wordings (29 training examples)\n", "    {\n", "        'query': \"I need to change the quantity of items in my order before it ships\",\n", "        'category': 'ORDER',\n", "        'reference': \"I understand you'd like to modify the quantity of items in your order before it ships. I'm here to help with that. To change your order quantity, please provide me with your order number and let me know which items you'd like to adjust and the new quantities you need. I'll check if your order is still in processing status - if it hasn't shipped yet, we should be able to make the changes. If it's already shipped, we can discuss options like refusing delivery or setting up a return for the excess items.\"\n", "    },\n", "    {\n", "        'query': \"Can I swap one product for another in my existing order?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I'd be happy to help you swap a product in your existing order. To assist you with this, I'll need your order number and details about which product you'd like to swap and what you'd like to replace it with. If your order hasn't shipped yet, we can often make this change directly. However, if it's already shipped, we'll need to process this as a return and new order. Let me check the status of your order - could you provide the order number?\"\n", "    },\n", "    {\n", "        'query': \"My order is processing but I realized I need it delivered to a different address\",\n", "        'category': 'ORDER',\n", "        'reference': \"I understand you need to change the delivery address for your order that's currently processing. Time is of the essence here. Please provide your order number immediately so I can check if we can still update the shipping address before it leaves our warehouse. If the order hasn't been dispatched yet, we should be able to change the address. If it's already shipped, we may be able to reroute it or arrange for a hold at a carrier facility. What's your order number?\"\n", "    },\n", "    {\n", "        'query': \"I accidentally ordered the wrong size, can I fix this before delivery?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I completely understand - ordering the wrong size is a common concern and we're here to help! To assist you, I'll need your order number to check the status. If your order is still processing and hasn't shipped, we can usually cancel it and place a new order with the correct size. If it's already shipped, don't worry - you can return the wrong size and we'll send you the correct size. What's your order number and what size do you actually need?\"\n", "    },\n", "    {\n", "        'query': \"Is it possible to split my order into two separate shipments?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I appreciate you reaching out about splitting your order into separate shipments. This request depends on the current status of your order. If it's still being processed, we may be able to split it, though this might affect shipping costs. If you have specific items you need urgently while others can wait, please provide your order number and specify which items you'd like in each shipment. I'll check what's possible and provide you with options, including any additional shipping fees that may apply.\"\n", "    },\n", "    {\n", "        'query': \"I want to add more items to an order I placed yesterday\",\n", "        'category': 'ORDER',\n", "        'reference': \"I understand you'd like to add more items to your order from yesterday. Unfortunately, once an order is placed, we typically cannot add items to it directly as our system begins processing immediately. However, I have a couple of solutions: 1) You can place a new separate order for the additional items, or 2) If your original order hasn't shipped yet, we might be able to cancel it and help you place a new combined order. Could you provide your order number so I can check the status and see which option would work best for you?\"\n", "    },\n", "    {\n", "        'query': \"My order shows delivered but I never received it, what should I do?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I'm very sorry to hear your order shows as delivered but you haven't received it. This is certainly concerning and we'll help resolve this immediately. First, please check: 1) All possible delivery locations (front door, back door, mailbox, building lobby), 2) With family members or neighbors who might have accepted it, 3) Any safe place instructions you provided. If you still can't locate it, please provide your order number and we'll: investigate with the carrier, file a claim if necessary, and either refund you or send a replacement. Your satisfaction is our priority.\"\n", "    }\n", "]\n", "\n", "# Load models\n", "print(\"\\nLoading models...\")\n", "\n", "# Load retrieval system\n", "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n", "train_embeddings = embedding_model.encode(\n", "    df_train_pilot['instruction'].tolist(),\n", "    show_progress_bar=False,\n", "    convert_to_numpy=True\n", ")\n", "index = faiss.IndexFlatL2(train_embeddings.shape[1])\n", "index.add(train_embeddings.astype('float32'))\n", "\n", "# Load fine-tuned LLM\n", "base_model = AutoModelForCausalLM.from_pretrained(\n", "    \"microsoft/phi-2\",\n", "    device_map=\"auto\",\n", "    trust_remote_code=True,\n", "    torch_dtype=torch.float16\n", ")\n", "llm_model = PeftModel.from_pretrained(\n", "    base_model,\n", "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n", ")\n", "llm_tokenizer = AutoTokenizer.from_pretrained(\n", "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n", ")\n", "print(\"\u2713 Models loaded\")\n", "\n", "# Test novel queries\n", "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n", "\n", "retrieval_scores = []\n", "llm_scores = []\n", "retrieval_distances = []\n", "\n", "print(\"\\n\" + \"=\"*70)\n", "print(\"TESTING NOVEL QUERIES\")\n", "print(\"=\"*70)\n", "\n", "for i, item in enumerate(novel_queries, 1):\n", "    query = item['query']\n", "    reference = item['reference']\n", "    category = item['category']\n", "\n", "    print(f\"\\n{'='*70}\")\n", "    print(f\"Query {i}/{len(novel_queries)} - Category: {category}\")\n", "    print(f\"Novel Query: {query}\")\n", "    print(\"-\"*70)\n", "\n", "    # RETRIEVAL\n", "    query_emb = embedding_model.encode([query], convert_to_numpy=True)\n", "    dist, ind = index.search(query_emb.astype('float32'), 1)\n", "    retrieved_resp = df_train_pilot.iloc[ind[0][0]]['response']\n", "    retrieved_query = df_train_pilot.iloc[ind[0][0]]['instruction']\n", "    retrieved_category = df_train_pilot.iloc[ind[0][0]]['category']\n", "\n", "    ret_score = rouge_scorer_obj.score(reference, retrieved_resp)['rougeL'].fmeasure\n", "    retrieval_distances.append(dist[0][0])\n", "\n", "    print(f\"\\nRetrieval:\")\n", "    print(f\"  Matched to: '{retrieved_query[:70]}...'\")\n", "    print(f\"  Matched category: {retrieved_category} {'\u2713' if retrieved_category == category else '\u2717 WRONG!'}\")\n", "    print(f\"  Distance: {dist[0][0]:.3f} {'(VERY FAR!)' if dist[0][0] > 1.0 else '(far)' if dist[0][0] > 0.5 else '(close)'}\")\n", "    print(f\"  ROUGE-L: {ret_score:.3f}\")\n", "    print(f\"  Response: {retrieved_resp[:120]}...\")\n", "\n", "    # LLM GENERATION\n", "    prompt = f\"Customer: {query}\\nAssistant:\"\n", "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(llm_model.device)\n", "    with torch.no_grad():\n", "        outputs = llm_model.generate(\n", "            **inputs,\n", "            max_new_tokens=200,\n", "            do_sample=True,\n", "            temperature=0.7,\n", "            top_p=0.9,\n", "            pad_token_id=llm_tokenizer.eos_token_id\n", "        )\n", "    llm_resp = llm_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n", "    llm_score = rouge_scorer_obj.score(reference, llm_resp)['rougeL'].fmeasure\n", "\n", "    print(f\"\\nLLM:\")\n", "    print(f\"  ROUGE-L: {llm_score:.3f}\")\n", "    print(f\"  Response: {llm_resp[:120]}...\")\n", "\n", "    # Determine winner\n", "    winner = \"\ud83d\udd25 LLM\" if llm_score > ret_score else \"\ud83d\udcda Retrieval\" if ret_score > llm_score else \"\ud83e\udd1d Tie\"\n", "    print(f\"\\n{winner} (\u0394 {abs(llm_score - ret_score):.3f})\")\n", "\n", "    retrieval_scores.append(ret_score)\n", "    llm_scores.append(llm_score)\n", "\n", "# Final results\n", "print(\"\\n\" + \"=\"*70)\n", "print(\"SPARSE CATEGORY STRESS TEST RESULTS\")\n", "print(\"=\"*70)\n", "\n", "print(f\"\\nRetrieval (sparse training data): {np.mean(retrieval_scores):.4f} ROUGE-L\")\n", "print(f\"LLM (trained on same data):       {np.mean(llm_scores):.4f} ROUGE-L\")\n", "\n", "print(f\"\\nAverage retrieval distance: {np.mean(retrieval_distances):.3f}\")\n", "print(f\"  (Higher = worse matches, <0.5 is good, >1.0 is bad)\")\n", "\n", "diff = np.mean(llm_scores) - np.mean(retrieval_scores)\n", "print(f\"\\nDifference: {diff:+.4f}\")\n", "\n", "llm_wins = sum([1 for l, r in zip(llm_scores, retrieval_scores) if l > r])\n", "ret_wins = sum([1 for l, r in zip(llm_scores, retrieval_scores) if r > l])\n", "ties = len(llm_scores) - llm_wins - ret_wins\n", "\n", "print(f\"\\nHead-to-head: LLM {llm_wins}/{len(novel_queries)}, Retrieval {ret_wins}/{len(novel_queries)}, Ties {ties}/{len(novel_queries)}\")\n", "\n", "print(\"\\n\" + \"=\"*70)\n", "print(\"KEY INSIGHT\")\n", "print(\"=\"*70)\n", "\n", "if diff > 0.05 and llm_wins > ret_wins:\n", "    print(\"\u2705 LLM DOMINATES on novel queries with sparse training data!\")\n", "    print(f\"   \u2192 With only {category_counts.min()}-{category_counts.iloc[1]} examples per sparse category, retrieval struggles\")\n", "    print(\"   \u2192 LLM learned patterns and can generalize to novel wordings\")\n", "    print(\"   \u2192 THIS IS THE VALUE OF FINE-TUNING!\")\n", "elif diff > 0:\n", "    print(\"\u26a0\ufe0f  LLM slightly better on sparse data\")\n", "    print(\"   \u2192 Results suggest LLM has some generalization advantage\")\n", "else:\n", "    print(\"\ud83d\udcda Retrieval holds up even on sparse data\")\n", "    print(\"   \u2192 Semantic embeddings capture similarity well\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000, "referenced_widgets": ["a019126bd52748ca87484c91bdf8756e", "e63c20d01c3b469d8c8479ee87666c52", "72029fceb6884938a5775275564be9a6", "1a8cf1acd3734f95aedcfa743b35cbf6", "5cb06a78294e4851986c375ef9448c1e", "67711889960d4184b301553e1fa3e26e", "d6d125adec1341a383a3f63874fe3dcb", "109f5b0f864c481e8f7889de22688a22", "053e0fc9b83c4e3eab1111f05d73a3c0", "f38845e1f3d846afb47a4a06c6fe2c69", "7fe475807e8e45cfabcf0910f572a8cb", "53c292591a8f4a22a7d7ecc7e5f523f5", "3b4034c112fb4f6c8f083d8aae7a681e", "02eca02a605c4f8ca0d946a9f3194cb2", "e6b675aab0044136a5726a6a2d1d0f08", "f2892979d82c4cb883f791e6a9285868", "78ce52b0f4a94b40bdb54c912a4350c4", "b0c5d74b83804521840d19da8040d9b1", "5a0f31e37d1141da9bf4cf044dab359b", "72985b17beeb4c53a7f14aaaec91056d", "ea656b6c79194e68a5a758127cfb2cb2", "052581e276284675b17a78db9947b0cd", "1430fbcb36814c2fb428b1a5414a72c7", "503cf2dcdfa14406a15d1889a8e7123e", "93546b19a1d64638961e8120bcea6255", "e756a3ac524a457aa1a44ca42bffc55e", "aa66335da56049f19fd245dfaab600fd", "2fd97dcadd97402badbf419fad2b2fab", "4aefbf8cc52445f59a743d46e180d4d9", "c39ae572d72845b18ae7125a1d1d9655", "8537debb646a4afaab5d29c3de174514", "ff43e5760308416799a2b597507d158d", "99e21bd2b2bc455d8fd8989d2cf0412f", "ccd00835d5a0474caadb73296ac66449", "1e5eacbe84bd4fb9847d1dc1ea56b8af", "5326a5879c4242398321f17f957317cc", "4baf31f4407d47eb898b6f3286c64fa6", "e1bbb8a67f13452aa5adc606aede9ec4", "20df9cbc54b348d194881c85a74b68cc", "83e00313d5b04805a4d6b6395e699d3b", "b238e314b1424ad798cbcf320aca65b5", "3cb67124c8f847a2b573c90cbe85f97b", "4cbe0b0dcf6945299648c45ec85fb7c7", "7ecd0a7595ea4eafbefa3d2051f7be5c", "b2298f7970c644989b7beebc0eef95de", "6b556b9e9bde4e41af027f2124e46107", "c8602181a5584661ababfed3e6ad21de", "41ab07f562584319acbab149ce32e503", "1a5d2cb0f504443ead699680c82054ea", "8d84ef67785b4ec7b459ccffe38d4a8f", "99a60c441ccf41a9a220887c90b47e9a", "478841a235fa416db7e0f25cc837337e", "afde50f77a6b455cb1359dae327c7390", "85bc4e6dcc2b425386cda30d9d3dd4dd", "7c7c6d5cdde64fddbcf3875e13783e3a", "30b3b70e4a8240968e95f8336cf4647d", "0ab531ab2d8b4d09aa8025640ad3659c", "d4905a3ac5bb4315a966038250853a9c", "bb0d02e2863249cba50d195352ade527", "e7c822dedc3e4457b68739d4ccec327c", "b725d2aa3ef3493585b2f496cf90df3a", "c0401576aeee45429ab8d88515b71911", "a548302e520041deb89945a725b9b57e", "437042ef10df4c6aa0e43a90ec02205c", "ea521ca6e85e40a58b9f387268fb2cb0", "63c9c159776c4a52a900e547ccaaaf55", "4d98649c04b24b0f889b76dc6fc39dff", "f57c331c02d34cddae5772aada100df4", "055eaefc26024c1f85bb673628661949", "4cde4d920ad340c5b4d08c99a7d3b2be", "a74b84ece9754753bbd2b35984f627e6", "e5db0b486ea14c329c51b894ac4220e6", "5dfc78f852b14d1ca863fe4491b1f43e", "d4b41a3f63644e66b5fd3edfd8710350", "b72800dff3a74cb4be23690481b353e9", "47183de0cc0341418a196d5d4a38b901", "8e68ee2f39ab4e68bba795c6429d490b", "2983b0d3580e4e32a2853dd3322ec322", "cee53eabd1cd40d39ebaedc485bddb1d", "6319ccbb890c44b2b91c20dd69c867d2", "498335eb86a14303b694f6861ec085a6", "a2b17a1093e74fd5b95450d53c455206", "0af0339bcc4c4deca9c5baed966ab28e", "dbbbd55295d34645a10a293fe31850e9", "56d0dbdf277b4ce29d6862504e435cbe", "4718de688897404ab409bf41da6f36ae", "8f8706d79b2b4e7db5e9afcc17182db8", "1aee584d4d20420e90652385b2ceaa0b", "6361d93abd584ac6859e45f0fb208ba4", "823a4410c72949a28493e953e7105661", "9def869c31644432a6cee5adc72e91ac", "fa4d054fa7ac4427ba8afc0105c35c04", "be58334a6beb43158adb7ebaa0529d5d", "f1afedda83c44713bae965bc5f6286cd", "d6761466b8ba4547b2a6063dacc3a10d", "20eba0d2a1a24e4eb828318aa8633c98", "1e4d87411dfa445a91b4fc2a12d670a9", "f625159aac8c4c1cb0ada8f0c69363f9", "68d77c880215426b9e65ca6ada8d66ca", "8933e9262c634798a0bd03c865c07b99", "2c53847775544911ae6d781849c077ce", "37b1e2f78283457dac72edf7e306dd00", "113f5bf3f019486e91665862730cce9e", "5f3eda353d594def88fdbed6616cc27d", "f4d1160fb2474382b8099ee5f306ea09", "e086cda6ea3d48bea9856d3dbd4e00a2", "ad3a43fb68034bbe94a29c4c9f653732", "971666e8cfaa46c6b5a445fcee3690cb", "557acfbba04b46829f817b6faa5e7403", "de0929b077da41d6914b5b481f1e3a98", "e91ef2c3634646cfbc25e7b6342d96f4", "623a00197fdb448d9e06ba6491cb8db6", "305b009bfc5649a0910a733d2d13a383", "8cecc67e17104cd791665f893d7fce59", "7b2b1e2fcae74b19bcab4389cd450db4", "59f204be5f12429e89a7a62c4532ad79", "5b3fdb1c58114ff9bb5308042f64d60e", "ec869f01f49a4d28a7ccac42dd29ac0b", "139e968e82564254a38ff0f4276e2b7c", "e8586521b686452ca15fd6ae987876d2", "6dece4ac1bda4b5b8d28b3feaac84aeb", "f1c8a688dbbf4a7aad8381bae0a9fd33", "78b86d64a8034eefa9cbd73d255beb62", "af6c3cccc0704065b1ac83064a605d93", "63dc9f62798140f8bde610134bc3205f", "f74e3855203c4e808b770e4b53bde73f", "6510adbdf58942eb966c3d58a9cfaf55", "3c9b37b0b9d8492abb4de9634b786529", "cb2c4a25502848bc8dc78b7ebc817547", "2293b679ae6945cab4acb286f7b75dcc", "20de65d377bb456eab9a88cb04f97be5", "823c20adcb15444c9182c825cd0f30b8"]}, "id": "lqoJHakkzUC4", "outputId": "8879a619-69cf-4268-f817-82ea9431bfd5"}, "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\n", "Loading models...\n"]}, {"output_type": "display_data", "data": {"text/plain": ["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a019126bd52748ca87484c91bdf8756e"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "53c292591a8f4a22a7d7ecc7e5f523f5"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["README.md: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "1430fbcb36814c2fb428b1a5414a72c7"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ccd00835d5a0474caadb73296ac66449"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b2298f7970c644989b7beebc0eef95de"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "30b3b70e4a8240968e95f8336cf4647d"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "4d98649c04b24b0f889b76dc6fc39dff"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["vocab.txt: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2983b0d3580e4e32a2853dd3322ec322"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer.json: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6361d93abd584ac6859e45f0fb208ba4"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8933e9262c634798a0bd03c865c07b99"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e91ef2c3634646cfbc25e7b6342d96f4"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "f1c8a688dbbf4a7aad8381bae0a9fd33"}}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["\u2713 Models loaded\n", "\n", "======================================================================\n", "TESTING NOVEL QUERIES\n", "======================================================================\n", "\n", "======================================================================\n", "Query 1/14 - Category: FEEDBACK\n", "Novel Query: I'd like to share my thoughts about the product quality and service I received\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I want to send feedback for your company, help me...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 0.871 (far)\n", "  ROUGE-L: 0.423\n", "  Response: I'm on it! Your willingness to share feedback is truly appreciated, as it helps us understand your experience better and...\n", "\n", "LLM:\n", "  ROUGE-L: 0.374\n", "  Response: Thank you for reaching out and sharing your thoughts about the product quality and service you received. Your feedback i...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.049)\n", "\n", "======================================================================\n", "Query 2/14 - Category: FEEDBACK\n", "Novel Query: Where can I write about my experience with your company?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I want to send feedback for your company, help me...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 0.938 (far)\n", "  ROUGE-L: 0.202\n", "  Response: I'm on it! Your willingness to share feedback is truly appreciated, as it helps us understand your experience better and...\n", "\n", "LLM:\n", "  ROUGE-L: 0.201\n", "  Response: Thank you for reaching out! I'd be happy to provide you with information on how to write about your experience with our ...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.002)\n", "\n", "======================================================================\n", "Query 3/14 - Category: FEEDBACK\n", "Novel Query: The shipping was fast but the product didn't meet my expectations - how do I let you know?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I don't know how I can submit feedback for your products...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 1.252 (VERY FAR!)\n", "  ROUGE-L: 0.268\n", "  Response: Thank you for your interest in providing feedback for our products! Your input is essential to us as it helps us improve...\n", "\n", "LLM:\n", "  ROUGE-L: 0.265\n", "  Response: We're sorry to hear that the product you received didn't meet your expectations. We appreciate your feedback, and we wan...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.003)\n", "\n", "======================================================================\n", "Query 4/14 - Category: FEEDBACK\n", "Novel Query: I want to give you guys a 5-star rating, what's the best way to do that?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I need to levae some feedback for a service, how do I do it?...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 1.290 (VERY FAR!)\n", "  ROUGE-L: 0.200\n", "  Response: Thank you for expressing your interest in leaving feedback for our service! We greatly value your input as it allows us ...\n", "\n", "LLM:\n", "  ROUGE-L: 0.171\n", "  Response: Thank you for your kind words and 5-star rating! We truly appreciate your support and trust in our services. Your feedba...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.029)\n", "\n", "======================================================================\n", "Query 5/14 - Category: FEEDBACK\n", "Novel Query: Can I post feedback about both the product and customer service in one place?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'can i send  feedback for ur services...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 0.511 (far)\n", "  ROUGE-L: 0.226\n", "  Response: Positively! We greatly appreciate your willingness to provide feedback for our services. Your insights and opinions are ...\n", "\n", "LLM:\n", "  ROUGE-L: 0.286\n", "  Response: Absolutely! We encourage you to share feedback about both the product and customer service in one place. We value your i...\n", "\n", "\ud83d\udd25 LLM (\u0394 0.060)\n", "\n", "======================================================================\n", "Query 6/14 - Category: FEEDBACK\n", "Novel Query: I had a mixed experience and want to tell you what went well and what didn't\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I want to send feedback for your company, help me...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 1.430 (VERY FAR!)\n", "  ROUGE-L: 0.261\n", "  Response: I'm on it! Your willingness to share feedback is truly appreciated, as it helps us understand your experience better and...\n", "\n", "LLM:\n", "  ROUGE-L: 0.195\n", "  Response: Thank you for sharing your feedback! We appreciate your honesty and value your input. We're glad to hear that you enjoye...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.066)\n", "\n", "======================================================================\n", "Query 7/14 - Category: FEEDBACK\n", "Novel Query: Is there a form where I can rate my recent purchase?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I have to check purchase {{Order Number}} status, I need help...'\n", "  Matched category: ORDER \u2717 WRONG!\n", "  Distance: 1.005 (VERY FAR!)\n", "  ROUGE-L: 0.205\n", "  Response: We're here to help! I take note that you need assistance with checking the status of your purchase with the purchase num...\n", "\n", "LLM:\n", "  ROUGE-L: 0.195\n", "  Response: Absolutely! You can rate your recent purchase on our website. Just navigate to the \"Account\" or \"Order History\" section ...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.010)\n", "\n", "======================================================================\n", "Query 8/14 - Category: ORDER\n", "Novel Query: I need to change the quantity of items in my order before it ships\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.741 (far)\n", "  ROUGE-L: 0.243\n", "  Response: Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is absolutely possible ...\n", "\n", "LLM:\n", "  ROUGE-L: 0.367\n", "  Response: I'm sorry to hear that you need to change the quantity of items in your order before it ships. I understand how importan...\n", "\n", "\ud83d\udd25 LLM (\u0394 0.125)\n", "\n", "======================================================================\n", "Query 9/14 - Category: ORDER\n", "Novel Query: Can I swap one product for another in my existing order?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I'm trying to swap a  product of order {{Order Number}}...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.597 (far)\n", "  ROUGE-L: 0.270\n", "  Response: We understand that you're attempting to swap a product from order number {{Order Number}}. We are here to assist you wit...\n", "\n", "LLM:\n", "  ROUGE-L: 0.177\n", "  Response: I'm glad to be of assistance. Don't hesitate to reach out if you need any further help. Have a great day!\n", "\n", "\n", "Imagine you ...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.092)\n", "\n", "======================================================================\n", "Query 10/14 - Category: ORDER\n", "Novel Query: My order is processing but I realized I need it delivered to a different address\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I need help locatin purchase {{Order Number}}...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 1.082 (VERY FAR!)\n", "  ROUGE-L: 0.212\n", "  Response: Thank you for contacting! I certainly recognize that you need assistance with locating your purchase with order number {...\n", "\n", "LLM:\n", "  ROUGE-L: 0.187\n", "  Response: We apologize for the inconvenience. Please provide us with the new address and we will update the shipping information a...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.025)\n", "\n", "======================================================================\n", "Query 11/14 - Category: ORDER\n", "Novel Query: I accidentally ordered the wrong size, can I fix this before delivery?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 1.165 (VERY FAR!)\n", "  ROUGE-L: 0.185\n", "  Response: Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is absolutely possible ...\n", "\n", "LLM:\n", "  ROUGE-L: 0.172\n", "  Response: We're sorry to hear that you accidentally ordered the wrong size. We understand that it can be frustrating when things d...\n", "\n", "\ud83d\udcda Retrieval (\u0394 0.013)\n", "\n", "======================================================================\n", "Query 12/14 - Category: ORDER\n", "Novel Query: Is it possible to split my order into two separate shipments?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.876 (far)\n", "  ROUGE-L: 0.211\n", "  Response: Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is absolutely possible ...\n", "\n", "LLM:\n", "  ROUGE-L: 0.237\n", "  Response: Hello! Yes, it is possible to split your order into two separate shipments. To initiate this process, please contact our...\n", "\n", "\ud83d\udd25 LLM (\u0394 0.026)\n", "\n", "======================================================================\n", "Query 13/14 - Category: ORDER\n", "Novel Query: I want to add more items to an order I placed yesterday\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.732 (far)\n", "  ROUGE-L: 0.220\n", "  Response: Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is absolutely possible ...\n", "\n", "LLM:\n", "  ROUGE-L: 0.304\n", "  Response: I'm sorry to hear that you want to add more items to your order from yesterday. I can certainly assist you with that. Co...\n", "\n", "\ud83d\udd25 LLM (\u0394 0.084)\n", "\n", "======================================================================\n", "Query 14/14 - Category: ORDER\n", "Novel Query: My order shows delivered but I never received it, what should I do?\n", "----------------------------------------------------------------------\n", "\n", "Retrieval:\n", "  Matched to: 'I have to check purchase {{Order Number}} status, I need help...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 1.044 (VERY FAR!)\n", "  ROUGE-L: 0.138\n", "  Response: We're here to help! I take note that you need assistance with checking the status of your purchase with the purchase num...\n", "\n", "LLM:\n", "  ROUGE-L: 0.249\n", "  Response: I'm sorry to hear that your order has not been delivered. I understand how frustrating this can be. To assist you furthe...\n", "\n", "\ud83d\udd25 LLM (\u0394 0.110)\n", "\n", "======================================================================\n", "SPARSE CATEGORY STRESS TEST RESULTS\n", "======================================================================\n", "\n", "Retrieval (sparse training data): 0.2332 ROUGE-L\n", "LLM (trained on same data):       0.2415 ROUGE-L\n", "\n", "Average retrieval distance: 0.967\n", "  (Higher = worse matches, <0.5 is good, >1.0 is bad)\n", "\n", "Difference: +0.0083\n", "\n", "Head-to-head: LLM 5/14, Retrieval 9/14, Ties 0/14\n", "\n", "======================================================================\n", "KEY INSIGHT\n", "======================================================================\n", "\u26a0\ufe0f  LLM slightly better on sparse data\n", "   \u2192 Results suggest LLM has some generalization advantage\n"]}]}, {"cell_type": "code", "source": ["novel_queries = [\n", "    # FEEDBACK category - 7 novel wordings (19 training examples)\n", "    {\n", "        'query': \"I'd like to share my thoughts about the product quality and service I received\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Thank you for your willingness to share your thoughts about the product quality and service you received. We greatly value your feedback as it helps us improve our offerings and customer experience. To submit your review, you can visit our website and navigate to the product page, where you'll find a review section. Alternatively, you can reply to your order confirmation email with your feedback. We appreciate you taking the time to share your experience!\"\n", "    },\n", "    {\n", "        'query': \"Where can I write about my experience with your company?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"We're thrilled that you want to share your experience with our company! Customer feedback is incredibly valuable to us. You can write about your experience in several ways: on our website's review section, by replying to your order confirmation email, through our social media pages, or on third-party review platforms. Which method would be most convenient for you? We look forward to hearing about your experience!\"\n", "    },\n", "    {\n", "        'query': \"The shipping was fast but the product didn't meet my expectations - how do I let you know?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Thank you for sharing this feedback with us, and I apologize that the product didn't meet your expectations despite our fast shipping. Your honest feedback is important to us. To formally submit your review, you can visit the product page on our website and leave a detailed review there. This helps both us and other customers. Additionally, I'd like to understand more about what didn't meet your expectations so we can address this concern properly.\"\n", "    },\n", "    {\n", "        'query': \"I want to give you guys a 5-star rating, what's the best way to do that?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"We're absolutely delighted to hear you want to give us a 5-star rating! Your positive feedback means the world to us. The best ways to leave your rating are: on our website's product or service page, through the review link in your order confirmation email, or on Google Reviews and other platforms. Your 5-star rating will help other customers discover our services. Thank you so much for taking the time to share your positive experience!\"\n", "    },\n", "    {\n", "        'query': \"Can I post feedback about both the product and customer service in one place?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Absolutely! We encourage comprehensive feedback that covers both product and customer service experience. You can post combined feedback on our website's review section, where you can rate and comment on multiple aspects of your experience. This holistic feedback is incredibly valuable as it gives us a complete picture of your customer journey. Feel free to be as detailed as you'd like - we read every review carefully!\"\n", "    },\n", "    {\n", "        'query': \"I had a mixed experience and want to tell you what went well and what didn't\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"We truly appreciate your honesty and willingness to share both the positive and negative aspects of your experience. Balanced feedback like yours is incredibly valuable as it helps us understand what we're doing right and where we need to improve. Please feel free to provide your detailed review on our website's feedback section or reply to your order confirmation email. We take all feedback seriously and use it to continuously enhance our products and services.\"\n", "    },\n", "    {\n", "        'query': \"Is there a form where I can rate my recent purchase?\",\n", "        'category': 'FEEDBACK',\n", "        'reference': \"Yes, there certainly is! We'd love to hear your thoughts on your recent purchase. You can find our rating and review form on the product page of our website. Simply navigate to the item you purchased, scroll to the review section, and you'll see the rating form. Alternatively, check your order confirmation email - it should contain a direct link to submit your rating. Your feedback helps both us and other customers make better decisions.\"\n", "    },\n", "\n", "    # ORDER category - 7 novel wordings (29 training examples)\n", "    {\n", "        'query': \"I need to change the quantity of items in my order before it ships\",\n", "        'category': 'ORDER',\n", "        'reference': \"I understand you'd like to modify the quantity of items in your order before it ships. I'm here to help with that. To change your order quantity, please provide me with your order number and let me know which items you'd like to adjust and the new quantities you need. I'll check if your order is still in processing status - if it hasn't shipped yet, we should be able to make the changes. If it's already shipped, we can discuss options like refusing delivery or setting up a return for the excess items.\"\n", "    },\n", "    {\n", "        'query': \"Can I swap one product for another in my existing order?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I'd be happy to help you swap a product in your existing order. To assist you with this, I'll need your order number and details about which product you'd like to swap and what you'd like to replace it with. If your order hasn't shipped yet, we can often make this change directly. However, if it's already shipped, we'll need to process this as a return and new order. Let me check the status of your order - could you provide the order number?\"\n", "    },\n", "    {\n", "        'query': \"My order is processing but I realized I need it delivered to a different address\",\n", "        'category': 'ORDER',\n", "        'reference': \"I understand you need to change the delivery address for your order that's currently processing. Time is of the essence here. Please provide your order number immediately so I can check if we can still update the shipping address before it leaves our warehouse. If the order hasn't been dispatched yet, we should be able to change the address. If it's already shipped, we may be able to reroute it or arrange for a hold at a carrier facility. What's your order number?\"\n", "    },\n", "    {\n", "        'query': \"I accidentally ordered the wrong size, can I fix this before delivery?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I completely understand - ordering the wrong size is a common concern and we're here to help! To assist you, I'll need your order number to check the status. If your order is still processing and hasn't shipped, we can usually cancel it and place a new order with the correct size. If it's already shipped, don't worry - you can return the wrong size and we'll send you the correct size. What's your order number and what size do you actually need?\"\n", "    },\n", "    {\n", "        'query': \"Is it possible to split my order into two separate shipments?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I appreciate you reaching out about splitting your order into separate shipments. This request depends on the current status of your order. If it's still being processed, we may be able to split it, though this might affect shipping costs. If you have specific items you need urgently while others can wait, please provide your order number and specify which items you'd like in each shipment. I'll check what's possible and provide you with options, including any additional shipping fees that may apply.\"\n", "    },\n", "    {\n", "        'query': \"I want to add more items to an order I placed yesterday\",\n", "        'category': 'ORDER',\n", "        'reference': \"I understand you'd like to add more items to your order from yesterday. Unfortunately, once an order is placed, we typically cannot add items to it directly as our system begins processing immediately. However, I have a couple of solutions: 1) You can place a new separate order for the additional items, or 2) If your original order hasn't shipped yet, we might be able to cancel it and help you place a new combined order. Could you provide your order number so I can check the status and see which option would work best for you?\"\n", "    },\n", "    {\n", "        'query': \"My order shows delivered but I never received it, what should I do?\",\n", "        'category': 'ORDER',\n", "        'reference': \"I'm very sorry to hear your order shows as delivered but you haven't received it. This is certainly concerning and we'll help resolve this immediately. First, please check: 1) All possible delivery locations (front door, back door, mailbox, building lobby), 2) With family members or neighbors who might have accepted it, 3) Any safe place instructions you provided. If you still can't locate it, please provide your order number and we'll: investigate with the carrier, file a claim if necessary, and either refund you or send a replacement. Your satisfaction is our priority.\"\n", "    }\n", "]"], "metadata": {"id": "Q7bw1dbh7_qG"}, "execution_count": 5, "outputs": []}, {"cell_type": "code", "source": ["import torch\n", "import numpy as np\n", "import faiss\n", "from sentence_transformers import SentenceTransformer\n", "from transformers import AutoModelForCausalLM, AutoTokenizer\n", "from peft import PeftModel\n", "from rouge_score import rouge_scorer\n", "from bert_score import BERTScorer\n", "\n", "# ------------------------------------------------------------------\n", "# 1. LOAD MODELS\n", "# ------------------------------------------------------------------\n", "print(\"\\nLoading models...\")\n", "\n", "# Load retrieval system (SentenceTransformers + FAISS)\n", "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n", "train_embeddings = embedding_model.encode(\n", "    df_train_pilot['instruction'].tolist(),\n", "    show_progress_bar=False,\n", "    convert_to_numpy=True\n", ")\n", "index = faiss.IndexFlatL2(train_embeddings.shape[1])\n", "index.add(train_embeddings.astype('float32'))\n", "\n", "# Load fine-tuned LLM\n", "base_model = AutoModelForCausalLM.from_pretrained(\n", "    \"microsoft/phi-2\",\n", "    device_map=\"auto\",\n", "    trust_remote_code=True,\n", "    torch_dtype=torch.float16\n", ")\n", "llm_model = PeftModel.from_pretrained(\n", "    base_model,\n", "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n", ")\n", "llm_tokenizer = AutoTokenizer.from_pretrained(\n", "    \"/content/drive/MyDrive/NLP_Project/checkpoints/phi2_lora_pilot/final_model\"\n", ")\n", "\n", "# Load Evaluators\n", "print(\"Loading Evaluators...\")\n", "rouge_scorer_obj = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n", "# lang=\"en\" downloads a standard model (usually roberta-large) for English\n", "bert_scorer = BERTScorer(lang=\"en\", rescale_with_baseline=False)\n", "\n", "print(\"\u2713 Models and Evaluators loaded\")\n", "\n", "# ------------------------------------------------------------------\n", "# 2. TEST NOVEL QUERIES\n", "# ------------------------------------------------------------------\n", "retrieval_rouge_scores = []\n", "retrieval_bert_scores = []\n", "llm_rouge_scores = []\n", "llm_bert_scores = []\n", "retrieval_distances = []\n", "\n", "print(\"\\n\" + \"=\"*70)\n", "print(\"TESTING NOVEL QUERIES (ROUGE & BERTSCORE)\")\n", "print(\"=\"*70)\n", "\n", "for i, item in enumerate(novel_queries, 1):\n", "    query = item['query']\n", "    reference = item['reference']\n", "    category = item['category']\n", "\n", "    print(f\"\\n{'='*70}\")\n", "    print(f\"Query {i}/{len(novel_queries)} - Category: {category}\")\n", "    print(f\"Novel Query: {query}\")\n", "    print(\"-\"*70)\n", "\n", "    # --- RETRIEVAL ---\n", "    query_emb = embedding_model.encode([query], convert_to_numpy=True)\n", "    dist, ind = index.search(query_emb.astype('float32'), 1)\n", "    retrieved_resp = df_train_pilot.iloc[ind[0][0]]['response']\n", "    retrieved_query = df_train_pilot.iloc[ind[0][0]]['instruction']\n", "    retrieved_category = df_train_pilot.iloc[ind[0][0]]['category']\n", "\n", "    # Calculate Scores (Retrieval)\n", "    ret_rouge = rouge_scorer_obj.score(reference, retrieved_resp)['rougeL'].fmeasure\n", "    # BERTScore returns P, R, F1 tensors. We take F1.\n", "    P, R, F1 = bert_scorer.score([retrieved_resp], [reference])\n", "    ret_bert = F1.item()\n", "\n", "    retrieval_distances.append(dist[0][0])\n", "\n", "    print(f\"\\n\ud83d\udcda Retrieval:\")\n", "    print(f\"  Matched to: '{retrieved_query[:70]}...'\")\n", "    print(f\"  Matched category: {retrieved_category} {'\u2713' if retrieved_category == category else '\u2717 WRONG!'}\")\n", "    print(f\"  Distance: {dist[0][0]:.3f}\")\n", "    print(f\"  ROUGE-L:   {ret_rouge:.3f}\")\n", "    print(f\"  BERTScore: {ret_bert:.3f}\")\n", "    print(f\"  Response:  {retrieved_resp[:100]}...\")\n", "\n", "    # --- LLM GENERATION ---\n", "    prompt = f\"Customer: {query}\\nAssistant:\"\n", "    inputs = llm_tokenizer(prompt, return_tensors=\"pt\").to(llm_model.device)\n", "    with torch.no_grad():\n", "        outputs = llm_model.generate(\n", "            **inputs,\n", "            max_new_tokens=200,\n", "            do_sample=True,\n", "            temperature=0.7,\n", "            top_p=0.9,\n", "            pad_token_id=llm_tokenizer.eos_token_id\n", "        )\n", "    llm_resp = llm_tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Assistant:\")[-1].strip()\n", "\n", "    # Calculate Scores (LLM)\n", "    llm_rouge = rouge_scorer_obj.score(reference, llm_resp)['rougeL'].fmeasure\n", "    P, R, F1 = bert_scorer.score([llm_resp], [reference])\n", "    llm_bert = F1.item()\n", "\n", "    print(f\"\\n\ud83d\udd25 LLM:\")\n", "    print(f\"  ROUGE-L:   {llm_rouge:.3f}\")\n", "    print(f\"  BERTScore: {llm_bert:.3f}\")\n", "    print(f\"  Response:  {llm_resp[:100]}...\")\n", "\n", "    # --- DETERMINE WINNER (Based on BERTScore) ---\n", "    # We use BERTScore for the 'winner' logic as it correlates better with human judgment\n", "    if llm_bert > ret_bert:\n", "        winner = \"\ud83d\udd25 LLM Wins\"\n", "    elif ret_bert > llm_bert:\n", "        winner = \"\ud83d\udcda Retrieval Wins\"\n", "    else:\n", "        winner = \"\ud83e\udd1d Tie\"\n", "\n", "    delta = abs(llm_bert - ret_bert)\n", "    print(f\"\\nRESULT: {winner} (BERTScore \u0394 {delta:.3f})\")\n", "\n", "    # Append to lists\n", "    retrieval_rouge_scores.append(ret_rouge)\n", "    retrieval_bert_scores.append(ret_bert)\n", "    llm_rouge_scores.append(llm_rouge)\n", "    llm_bert_scores.append(llm_bert)\n", "\n", "# ------------------------------------------------------------------\n", "# 3. FINAL RESULTS\n", "# ------------------------------------------------------------------\n", "print(\"\\n\" + \"=\"*70)\n", "print(\"FINAL PERFORMANCE METRICS\")\n", "print(\"=\"*70)\n", "\n", "print(f\"Metric       | Retrieval Avg | LLM Avg | Difference\")\n", "print(\"-\" * 55)\n", "print(f\"ROUGE-L      | {np.mean(retrieval_rouge_scores):.4f}        | {np.mean(llm_rouge_scores):.4f}  | {np.mean(llm_rouge_scores) - np.mean(retrieval_rouge_scores):+.4f}\")\n", "print(f\"BERTScore    | {np.mean(retrieval_bert_scores):.4f}        | {np.mean(llm_bert_scores):.4f}  | {np.mean(llm_bert_scores) - np.mean(retrieval_bert_scores):+.4f}\")\n", "\n", "print(\"-\" * 55)\n", "print(f\"Avg Ret Distance: {np.mean(retrieval_distances):.3f}\")\n", "\n", "# Calculate Win Rates (based on BERTScore)\n", "llm_wins = sum([1 for l, r in zip(llm_bert_scores, retrieval_bert_scores) if l > r])\n", "ret_wins = sum([1 for l, r in zip(llm_bert_scores, retrieval_bert_scores) if r > l])\n", "ties = len(llm_bert_scores) - llm_wins - ret_wins\n", "\n", "print(f\"\\nHead-to-head (BERTScore): LLM {llm_wins}, Retrieval {ret_wins}, Ties {ties}\")\n", "\n", "print(\"\\n\" + \"=\"*70)\n", "print(\"KEY INSIGHT\")\n", "print(\"=\"*70)\n", "\n", "diff_bert = np.mean(llm_bert_scores) - np.mean(retrieval_bert_scores)\n", "\n", "if diff_bert > 0.02:\n", "    print(\"\u2705 LLM DOMINATES on semantic meaning!\")\n", "    print(\"   \u2192 The BERTScore indicates the LLM is generating responses that share\")\n", "    print(\"     more *meaning* with the reference, even if exact words differ.\")\n", "elif diff_bert > 0:\n", "    print(\"\u26a0\ufe0f  LLM slightly better on semantic meaning\")\n", "else:\n", "    print(\"\ud83d\udcda Retrieval is more semantically accurate\")\n", "    print(\"   \u2192 The training data might be covering these queries well enough\")\n", "    print(\"     that the retrieval system's exact matches are superior.\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000, "referenced_widgets": ["849aaa01cc0748fa9b30248f2feb510e", "e5f11483d4f1409fb4eb551e09f2faa8", "c9d7ab28e8a84bcfb3e7f8689d7d8eb8", "c40933fa48664d8bbcb48d86c0ef4d88", "503fd49ed47b4d089246b300cc3c8af3", "1179413b67154899b392d237f6f4f995", "9d1e2a6bbc6643399192b58a37abeb9a", "55406d7ef8fd4082a61cfb253baa708c", "1dce0d6b2fd14c2885dc594893d14f09", "cdf14c3cce70485684dfa0dc77485c02", "8c0d759e9a1c43e8bb55988da0aa86cd", "0fd0bf3eca894b6f8ad4d20a127d2094", "3bea753d5e7d427ea750c1192ba0a50c", "3ec62f853ed4466bb525420d11d51b24", "d441bd39167f474ea597622bcb636f56", "ec1002bc18514eb9a97c77e9914e172f", "76376266ab0b426aa83b0384a52ec1d6", "cabb30782a534524bb2946a69eef51fc", "7a84ee3b26d946dd9fafd6c9d82ab4af", "9876bdd79ee646d386d51896d9f55e96", "d4a869cc907a40dfa128a061da28331e", "f135401061724a2bbc2f5ab8af419a00", "2847db23bb5a43248d0d8c48da25bd65", "83ac817882ca450fb16bd3b8698723e8", "ac76625138ec48748e7b4faad11a4d8e", "8ebd83310c57493f8a13e84e8f2543d7", "29253132878d438eb4e5c6866629f5e3", "2212906949094ba4a80703e4123c26c7", "40188aa0cbdc4d19aed2a90ca448227c", "48a94738b0794afb85a2ba78ec895fb7", "2faa0e99284c499b8574ea01fd3b7e19", "f244ca233f784a73b68d0bb645d4ee92", "d14dbffb3e1e44c59365a8ae09ed8fdf", "98fba3b3bd8749128c770cf5463d1991", "5e30910a5af04e429e1d87e64b7f8802", "881d2f7bc8b94a95b4ec1d9a032e83ae", "568175aa59f44c6abb2cda0faa2de812", "d010b8a3319447918e6741c2b23199f7", "f68bd56f9f6248518244884ee5673f16", "270e2fde406141b289ada4742038ee4f", "d4d09ea876e14ceeaaa0d3e9cdcee5d8", "bec6e306d42c47cb8c82e3b96ece26e4", "372a79ebad114c629a6762ec5d343830", "4125f87a0e41447fbe57532513d5fa62", "294e699657b94a789b4dac92570720fb", "136a50a911464e0592623c80cd1875cf", "d134b25bc26e44f3b92108f22bbe7c3e", "076612181a554c769b8ca230d04669fe", "4f2d8e508bc54fa3b69ef8e2bbca43a0", "91a1391c32d64e1a9c3b69fdab5215db", "ea519f28a78549778fa72aff5d9ee373", "a74e670762fc4a2ca52e19dd4c5604a5", "67541ab262d74445a16f1ec55864411e", "3ac67c3b3d8b47f1a05ff880001a41aa", "241947e6057d49b4a8f21d2fbc6d30a8", "5b8a826efba44beda781762daac09d06", "0c129dc8863444a49984e91ecc194f62", "6136157dcd73493ab770af5b88ca54ce", "de7c317d9ca3479f88657c63b66cc09a", "5759b522581c4156ae341b8372d52102", "25e2e791ae7d47b888c40cf60822cee9", "a3e5c7ab9b0e4336a6828bee6029a9a3", "03e0bb4a1481485786314e77d56ab3ac", "c025bc6a7e5f4fa9b3612b336e4d040a", "11d29a86b8a8405398eae832e30a4638", "a46887243e634beb9e3ef046dc902789", "2390074a4fd24d39ae66cd14ad55ca3e", "6a8f9848690c4096926d71266ce5c2ea", "99b6800a564e4725b4195bcc13b24412", "8c7ebb3828804a1390cc1f3d491d9320", "28a9ba015afd4d30a6702f0efaa52134", "5e0650ea0af34d84b7ea2468e0824286", "9359787a5d604e20aec9087c544c926d", "55cd738b885b4a87829077242550acd2", "29e08a06d35648bd8f81eed02532b945", "859dbe96616244ba8c65fe0412f94db3", "cf23f1dbd8dc43d18069cbbbea54633c", "1447f17824e14205bfc4c2b543abe28f", "f3df7175563d42c0ae3882d7d6f4524a", "792e70d450084faeb1f562ba42b9bace", "ed03eed137744b6fa30188b2f36faf93", "febe4f672c4d49dc93d0e9da7ca38120", "6294cb69c98f42be9dd635edc4ee07cd", "4e0b304a2790406fa1628100d590aad3", "0c752c17b62d404f8ceee7db2ca5bcc0", "022b4d963b364b9f9bd3ae1219a58ae0", "0e296b59b180447eaa8aa0696727df80", "ad11b494813b4af7814bf9924bd3d1af", "790f99a822104c12a172846236e26d9c", "a53bd18da0f24149af5788fa545c0ae7", "d65319b72d674eee8650f44e3ab108e0", "03b44aa0c16845888ab395f5459cdd40", "919a294da25a4b74a8fb1dd7d72a696e", "e8180278d1114f8c9f172b8e18f46a6f", "f7c1f2b849794b06ac4598a65c898412", "521e2e686e934808a9ebcf98fcd9209e", "ce1baeaa94bb43c192a4aa5265a5c6d3", "827d2f3be1a341bb9572b9f500bd1014", "08edf73ab5044b758e43c3e9a84e68e8", "d4129e8d80c94e1586702dcdaa0c47ad", "b15cf7557f9f4643975e80d3d812a39a", "9be9b7809dec4e3c9d316b60784b52ae", "ad14d52fafb24fe389bc547fd3950e3f", "aed6186e35234456942bf13f636c22fc", "e479656b9c1f4414a58394fc684244f4", "2425644d39d64f178a7fbae52f82fcdc", "8c1055e90b6a4cc19ac45b76e5760449", "9707dc98b20b460190261fe6c3620d0d", "83bb17a18dfb4846945977bc60b1a664", "4579661c835446e5b6718b292400e4ed", "9ed4ee810c6d4b10b69ae923c631e8c1", "1ea8f61b99cb45e3b9de979aa68c32a1", "15423e06fedd4b5ea7c10d0f46983b90", "4ceccf7ffa6b4ea39812f5b194af2957", "080de4a55e5f44ffb0795073e94340a4", "57069a2f28f543509a6475bf862a5430", "c32b44c309ac48ffa32927d4d41c6874", "c32017578fda45dbbd9f8bbf48d1b6a9", "51ea39c9c99f4a3198107bfbb1ba6a3d", "a6ef20747834487bbb5bef07f1c650e5", "baca93bf9cfe4c9aaa7a5e582a5577bf", "a7635d1683ba423b83418b21f67a982b", "f25bd842aa364bc5a79dc86cdb57a969", "76ebe8857cf8445c9646efc770992859", "d96b0764b9504ac5abbbc2bc38843945", "5ccb11a6f5884d8ab5743facb4c0ebdd", "53c32a5442514dcf8be5e97b3b259deb", "aa6379c0afb242919ed4d78378f10e97", "fc650fd8d0f54b3b8f591ec9241bd817", "0b012c4a30ed4c3ca169cbc556b1054c", "b98f9662f0e84fc299cf8728cfeaad7c", "fff604d2951d4e4bbc5414a7b9da54eb", "0b50d5b9df8145f896c039bcbf943c7a", "d3c0cd9fadcf4ff386dc9231803b9101", "6149ed4bc37241b8b0e3d2b1a909644f", "6e63c6aa0a6c42d1beb055595635385b", "5024c2554178422e9e553c31a71789dc", "978a2bc814bf456aa735ffc60a62e92c", "280bc24e6ca34249a80ced60a8fddcd2", "272abd0387df4b52a8ae73ad9c70ed23", "0237491e805f40608f07fd7b78f661f6", "b52f192ee6b5486885f9c66d9d9afec1", "61acb1f559134e01b9009f9a7b608429"]}, "id": "wOx0xjvu7-By", "outputId": "4871d58b-d3b3-4b43-cfa0-bb5e95cfea7f"}, "execution_count": 8, "outputs": [{"output_type": "stream", "name": "stdout", "text": ["\n", "Loading models...\n"]}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "849aaa01cc0748fa9b30248f2feb510e"}}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["`torch_dtype` is deprecated! Use `dtype` instead!\n"]}, {"output_type": "display_data", "data": {"text/plain": ["model.safetensors.index.json: 0.00B [00:00, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0fd0bf3eca894b6f8ad4d20a127d2094"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2847db23bb5a43248d0d8c48da25bd65"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "98fba3b3bd8749128c770cf5463d1991"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "294e699657b94a789b4dac92570720fb"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5b8a826efba44beda781762daac09d06"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "2390074a4fd24d39ae66cd14ad55ca3e"}}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": ["Loading Evaluators...\n"]}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "1447f17824e14205bfc4c2b543abe28f"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "790f99a822104c12a172846236e26d9c"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d4129e8d80c94e1586702dcdaa0c47ad"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9ed4ee810c6d4b10b69ae923c631e8c1"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a7635d1683ba423b83418b21f67a982b"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": ["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"], "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0b50d5b9df8145f896c039bcbf943c7a"}}, "metadata": {}}, {"output_type": "stream", "name": "stderr", "text": ["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n", "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}, {"output_type": "stream", "name": "stdout", "text": ["\u2713 Models and Evaluators loaded\n", "\n", "======================================================================\n", "TESTING NOVEL QUERIES (ROUGE & BERTSCORE)\n", "======================================================================\n", "\n", "======================================================================\n", "Query 1/14 - Category: FEEDBACK\n", "Novel Query: I'd like to share my thoughts about the product quality and service I received\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I want to send feedback for your company, help me...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 0.871\n", "  ROUGE-L:   0.423\n", "  BERTScore: 0.906\n", "  Response:  I'm on it! Your willingness to share feedback is truly appreciated, as it helps us understand your e...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.331\n", "  BERTScore: 0.899\n", "  Response:  We appreciate your feedback on the product quality and service you received. Your thoughts and opini...\n", "\n", "RESULT: \ud83d\udcda Retrieval Wins (BERTScore \u0394 0.007)\n", "\n", "======================================================================\n", "Query 2/14 - Category: FEEDBACK\n", "Novel Query: Where can I write about my experience with your company?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I want to send feedback for your company, help me...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 0.938\n", "  ROUGE-L:   0.202\n", "  BERTScore: 0.872\n", "  Response:  I'm on it! Your willingness to share feedback is truly appreciated, as it helps us understand your e...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.331\n", "  BERTScore: 0.888\n", "  Response:  Thank you for reaching out! We greatly appreciate your feedback and would be happy to hear about you...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.016)\n", "\n", "======================================================================\n", "Query 3/14 - Category: FEEDBACK\n", "Novel Query: The shipping was fast but the product didn't meet my expectations - how do I let you know?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I don't know how I can submit feedback for your products...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 1.252\n", "  ROUGE-L:   0.268\n", "  BERTScore: 0.893\n", "  Response:  Thank you for your interest in providing feedback for our products! Your input is essential to us as...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.146\n", "  BERTScore: 0.867\n", "  Response:  The customer is dissatisfied with the product and wants to let the company know. They are willing to...\n", "\n", "RESULT: \ud83d\udcda Retrieval Wins (BERTScore \u0394 0.027)\n", "\n", "======================================================================\n", "Query 4/14 - Category: FEEDBACK\n", "Novel Query: I want to give you guys a 5-star rating, what's the best way to do that?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I need to levae some feedback for a service, how do I do it?...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 1.290\n", "  ROUGE-L:   0.200\n", "  BERTScore: 0.867\n", "  Response:  Thank you for expressing your interest in leaving feedback for our service! We greatly value your in...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.277\n", "  BERTScore: 0.888\n", "  Response:  Thank you for considering giving us a 5-star rating! We truly appreciate your support. To leave us a...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.021)\n", "\n", "======================================================================\n", "Query 5/14 - Category: FEEDBACK\n", "Novel Query: Can I post feedback about both the product and customer service in one place?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'can i send  feedback for ur services...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 0.511\n", "  ROUGE-L:   0.226\n", "  BERTScore: 0.872\n", "  Response:  Positively! We greatly appreciate your willingness to provide feedback for our services. Your insigh...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.228\n", "  BERTScore: 0.887\n", "  Response:  Absolutely! Our platform allows you to provide feedback on both the product and customer service in ...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.015)\n", "\n", "======================================================================\n", "Query 6/14 - Category: FEEDBACK\n", "Novel Query: I had a mixed experience and want to tell you what went well and what didn't\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I want to send feedback for your company, help me...'\n", "  Matched category: FEEDBACK \u2713\n", "  Distance: 1.430\n", "  ROUGE-L:   0.261\n", "  BERTScore: 0.883\n", "  Response:  I'm on it! Your willingness to share feedback is truly appreciated, as it helps us understand your e...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.196\n", "  BERTScore: 0.875\n", "  Response:  Thank you for your email and for sharing your feedback with us. We value your input and appreciate y...\n", "\n", "RESULT: \ud83d\udcda Retrieval Wins (BERTScore \u0394 0.008)\n", "\n", "======================================================================\n", "Query 7/14 - Category: FEEDBACK\n", "Novel Query: Is there a form where I can rate my recent purchase?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I have to check purchase {{Order Number}} status, I need help...'\n", "  Matched category: ORDER \u2717 WRONG!\n", "  Distance: 1.005\n", "  ROUGE-L:   0.205\n", "  BERTScore: 0.865\n", "  Response:  We're here to help! I take note that you need assistance with checking the status of your purchase w...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.263\n", "  BERTScore: 0.888\n", "  Response:  Yes, we do have a feedback form for you to rate your recent purchase. I will provide you with the li...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.023)\n", "\n", "======================================================================\n", "Query 8/14 - Category: ORDER\n", "Novel Query: I need to change the quantity of items in my order before it ships\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.741\n", "  ROUGE-L:   0.243\n", "  BERTScore: 0.876\n", "  Response:  Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is ...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.313\n", "  BERTScore: 0.902\n", "  Response:  We appreciate your desire to change the quantity of items in your order. To assist you with this req...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.026)\n", "\n", "======================================================================\n", "Query 9/14 - Category: ORDER\n", "Novel Query: Can I swap one product for another in my existing order?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I'm trying to swap a  product of order {{Order Number}}...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.597\n", "  ROUGE-L:   0.270\n", "  BERTScore: 0.894\n", "  Response:  We understand that you're attempting to swap a product from order number {{Order Number}}. We are he...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.240\n", "  BERTScore: 0.877\n", "  Response:  I'm sorry to hear that you are not satisfied with one of the products you received. While we strive ...\n", "\n", "RESULT: \ud83d\udcda Retrieval Wins (BERTScore \u0394 0.017)\n", "\n", "======================================================================\n", "Query 10/14 - Category: ORDER\n", "Novel Query: My order is processing but I realized I need it delivered to a different address\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I need help locatin purchase {{Order Number}}...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 1.082\n", "  ROUGE-L:   0.212\n", "  BERTScore: 0.851\n", "  Response:  Thank you for contacting! I certainly recognize that you need assistance with locating your purchase...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.291\n", "  BERTScore: 0.877\n", "  Response:  I'm sorry to hear that you need to change the delivery address for your order. We understand that th...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.026)\n", "\n", "======================================================================\n", "Query 11/14 - Category: ORDER\n", "Novel Query: I accidentally ordered the wrong size, can I fix this before delivery?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 1.165\n", "  ROUGE-L:   0.185\n", "  BERTScore: 0.865\n", "  Response:  Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is ...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.258\n", "  BERTScore: 0.878\n", "  Response:  Hello! I'm here to assist you with any size-related concerns regarding your order. If you have order...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.013)\n", "\n", "======================================================================\n", "Query 12/14 - Category: ORDER\n", "Novel Query: Is it possible to split my order into two separate shipments?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.876\n", "  ROUGE-L:   0.211\n", "  BERTScore: 0.874\n", "  Response:  Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is ...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.190\n", "  BERTScore: 0.877\n", "  Response:  Yes, it is possible to split your order into two separate shipments. However, we need to ensure that...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.003)\n", "\n", "======================================================================\n", "Query 13/14 - Category: ORDER\n", "Novel Query: I want to add more items to an order I placed yesterday\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'is it possible to order some of ur item...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 0.732\n", "  ROUGE-L:   0.220\n", "  BERTScore: 0.867\n", "  Response:  Thank you for your interest in placing an order for our items! We appreciate your enthusiasm. It is ...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.194\n", "  BERTScore: 0.869\n", "  Response:  Thank you for reaching out! I'm here to assist you with adding more items to your order. To proceed,...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.002)\n", "\n", "======================================================================\n", "Query 14/14 - Category: ORDER\n", "Novel Query: My order shows delivered but I never received it, what should I do?\n", "----------------------------------------------------------------------\n", "\n", "\ud83d\udcda Retrieval:\n", "  Matched to: 'I have to check purchase {{Order Number}} status, I need help...'\n", "  Matched category: ORDER \u2713\n", "  Distance: 1.044\n", "  ROUGE-L:   0.138\n", "  BERTScore: 0.845\n", "  Response:  We're here to help! I take note that you need assistance with checking the status of your purchase w...\n", "\n", "\ud83d\udd25 LLM:\n", "  ROUGE-L:   0.220\n", "  BERTScore: 0.865\n", "  Response:  I'm sorry to hear that you haven't received your order. I understand how frustrating that can be. To...\n", "\n", "RESULT: \ud83d\udd25 LLM Wins (BERTScore \u0394 0.019)\n", "\n", "======================================================================\n", "FINAL PERFORMANCE METRICS\n", "======================================================================\n", "Metric       | Retrieval Avg | LLM Avg | Difference\n", "-------------------------------------------------------\n", "ROUGE-L      | 0.2332        | 0.2485  | +0.0152\n", "BERTScore    | 0.8736        | 0.8812  | +0.0076\n", "-------------------------------------------------------\n", "Avg Ret Distance: 0.967\n", "\n", "Head-to-head (BERTScore): LLM 10, Retrieval 4, Ties 0\n", "\n", "======================================================================\n", "KEY INSIGHT\n", "======================================================================\n", "\u26a0\ufe0f  LLM slightly better on semantic meaning\n"]}]}, {"cell_type": "code", "source": [], "metadata": {"id": "C_SXWjxV8Mpg"}, "execution_count": null, "outputs": []}]}